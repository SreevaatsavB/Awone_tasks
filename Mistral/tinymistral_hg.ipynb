{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import set_seed\n",
    "import torch\n",
    "\n",
    "SEED = 6\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralConfig {\n",
       "  \"_name_or_path\": \"./tiny-mistral\",\n",
       "  \"architectures\": [\n",
       "    \"MistralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"dropout_p\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 8,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mistral\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 1,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 3,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.38.0.dev0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, MistralConfig\n",
    "\n",
    "\n",
    "mistral_config = MistralConfig.from_pretrained(\"openaccess-ai-collective/tiny-mistral\", num_hidden_layers = 1, use_cache = False, hidden_size = 8, num_attention_heads = 4, \n",
    "                                           output_hidden_states=True,  num_key_value_heads = 2, past_key_values = True, intermediate_size = 8, sliding_window = 3, dropout_p = 0)\n",
    "\n",
    "\n",
    "mistral_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "tinymistral = AutoModel.from_config(mistral_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "src_sent = \"hi how are you doing\"\n",
    "\n",
    "mistal_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict = mistal_tokenizer.encode_plus(src_sent, return_tensors='pt')\n",
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 12014,   910,   460,   368,  2548]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized = tokenized_src_dict[\"input_ids\"]\n",
    "src_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hi how are you doing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistal_tokenizer.decode(*src_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "pprint(tokenized_src_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.ones>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = src_tokenized.shape[1]\n",
    "sliding_window_len = 3\n",
    "\n",
    "sliding_window_mask = 1 - (torch.triu(torch.ones(seq_length, seq_length), diagonal=1))\n",
    "\n",
    "\n",
    "for i in range(sliding_window_mask.shape[0]-1, -1, -1):\n",
    "\n",
    "    li = i - sliding_window_len + 1\n",
    "\n",
    "\n",
    "    if li > 0:\n",
    "\n",
    "        sliding_window_mask[i][0:li] = 0\n",
    "\n",
    "sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 6, 6]),\n",
       " tensor([[[[1., 0., 0., 0., 0., 0.],\n",
       "           [1., 1., 0., 0., 0., 0.],\n",
       "           [1., 1., 1., 0., 0., 0.],\n",
       "           [0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 1., 1., 1., 0.],\n",
       "           [0., 0., 0., 1., 1., 1.]]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask.shape, sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[[[1., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 1., 1., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0.],\n",
      "          [0., 0., 0., 1., 1., 1.]]]]),\n",
      " 'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]])}\n"
     ]
    }
   ],
   "source": [
    "tokenized_src_dict[\"attention_mask\"] = sliding_window_mask\n",
    "\n",
    "pprint(tokenized_src_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdpa\n",
      "\n",
      "###########################################################################\n",
      "LLAMA DECODER FWD START\n",
      "\n",
      "Attention mask =  tensor([[[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]]]])\n",
      "\n",
      "Input (hidden states) =  tensor([[[-0.0074, -0.0254,  0.0067,  0.0112,  0.0315,  0.0374,  0.0165,\n",
      "          -0.0181],\n",
      "         [-0.0131,  0.0218,  0.0225,  0.0525,  0.0102,  0.0363,  0.0032,\n",
      "          -0.0137],\n",
      "         [-0.0309,  0.0209, -0.0214,  0.0265, -0.0147, -0.0243,  0.0350,\n",
      "           0.0250],\n",
      "         [-0.0138, -0.0130,  0.0139,  0.0085, -0.0049,  0.0009, -0.0071,\n",
      "           0.0084],\n",
      "         [ 0.0376, -0.0126,  0.0067, -0.0009,  0.0185, -0.0372, -0.0128,\n",
      "           0.0204],\n",
      "         [-0.0160,  0.0149,  0.0070, -0.0099, -0.0118, -0.0123,  0.0177,\n",
      "           0.0366]]], grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "LayerNorm(hidden states) =  tensor([[[-0.3321, -1.1450,  0.3039,  0.5057,  1.4174,  1.6856,  0.7422,\n",
      "          -0.8167],\n",
      "         [-0.4934,  0.8224,  0.8510,  1.9829,  0.3837,  1.3713,  0.1228,\n",
      "          -0.5167],\n",
      "         [-1.2029,  0.8125, -0.8324,  1.0307, -0.5720, -0.9447,  1.3599,\n",
      "           0.9734],\n",
      "         [-1.3384, -1.2590,  1.3482,  0.8278, -0.4802,  0.0843, -0.6869,\n",
      "           0.8108],\n",
      "         [ 1.6819, -0.5647,  0.2996, -0.0414,  0.8280, -1.6612, -0.5732,\n",
      "           0.9095],\n",
      "         [-0.8816,  0.8184,  0.3826, -0.5416, -0.6470, -0.6772,  0.9711,\n",
      "           2.0128]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "position_ids =  tensor([[0, 1, 2, 3, 4, 5]])\n",
      "bsz, query_len  =  1 6\n",
      "\n",
      "query =  tensor([[[-0.0113, -0.0217, -0.0369, -0.0231,  0.0018,  0.0096, -0.0120,\n",
      "           0.0402],\n",
      "         [-0.0510, -0.0522, -0.0510, -0.0357, -0.0565,  0.0447,  0.0820,\n",
      "          -0.0111],\n",
      "         [-0.0135,  0.0034,  0.0354, -0.0907, -0.0300,  0.0246,  0.0032,\n",
      "          -0.0650],\n",
      "         [ 0.0072,  0.0276, -0.0701,  0.0316,  0.0627,  0.1072, -0.0125,\n",
      "           0.0886],\n",
      "         [ 0.0131,  0.0458,  0.0538,  0.0604, -0.0282,  0.0249, -0.0474,\n",
      "          -0.0304],\n",
      "         [-0.0426,  0.0593,  0.0134, -0.0548,  0.0401,  0.0886,  0.0021,\n",
      "          -0.0048]]], grad_fn=<UnsafeViewBackward0>)\n",
      "key =  tensor([[[-0.0682,  0.0924, -0.0166,  0.0247],\n",
      "         [-0.0963, -0.0072, -0.0289,  0.0196],\n",
      "         [-0.0226, -0.1110, -0.0446,  0.0053],\n",
      "         [ 0.0608, -0.0750, -0.0111, -0.0111],\n",
      "         [ 0.0157,  0.0671,  0.0796, -0.0588],\n",
      "         [ 0.0609, -0.1770, -0.0375,  0.0568]]], grad_fn=<UnsafeViewBackward0>)\n",
      "value =  tensor([[[-0.0372, -0.0752, -0.0424,  0.0104],\n",
      "         [-0.0334, -0.1026,  0.0050, -0.0126],\n",
      "         [-0.0387,  0.0184,  0.0497, -0.0733],\n",
      "         [-0.0112, -0.0671, -0.0189, -0.0172],\n",
      "         [-0.0131,  0.0943, -0.0999, -0.0100],\n",
      "         [ 0.1154,  0.0390,  0.0345, -0.0383]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "torch.Size([1, 6, 8]) torch.Size([1, 6, 4]) torch.Size([1, 6, 4])\n",
      "\n",
      "torch.Size([1, 4, 6, 2]) torch.Size([1, 2, 6, 2]) torch.Size([1, 2, 6, 2])\n",
      "\n",
      "kv_seq_len =  6\n",
      "\n",
      "max_position_embeddings =  32768\n",
      "Cos =  tensor([[ 1.0000,  1.0000],\n",
      "        [ 0.5403,  0.5403],\n",
      "        [-0.4161, -0.4161],\n",
      "        [-0.9900, -0.9900],\n",
      "        [-0.6536, -0.6536],\n",
      "        [ 0.2837,  0.2837]])\n",
      "\n",
      "Sin =  tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.8415,  0.8415],\n",
      "        [ 0.9093,  0.9093],\n",
      "        [ 0.1411,  0.1411],\n",
      "        [-0.7568, -0.7568],\n",
      "        [-0.9589, -0.9589]])\n",
      "\n",
      "Rotated query =  tensor([[[[-0.0113, -0.0217],\n",
      "          [ 0.0164, -0.0711],\n",
      "          [ 0.0026, -0.0137],\n",
      "          [-0.0110, -0.0263],\n",
      "          [ 0.0261, -0.0399],\n",
      "          [ 0.0448,  0.0577]],\n",
      "\n",
      "         [[-0.0369, -0.0231],\n",
      "          [ 0.0025, -0.0622],\n",
      "          [ 0.0677,  0.0699],\n",
      "          [ 0.0649, -0.0412],\n",
      "          [ 0.0105, -0.0802],\n",
      "          [-0.0488, -0.0284]],\n",
      "\n",
      "         [[ 0.0018,  0.0096],\n",
      "          [-0.0681, -0.0234],\n",
      "          [-0.0098, -0.0375],\n",
      "          [-0.0772, -0.0972],\n",
      "          [ 0.0373,  0.0051],\n",
      "          [ 0.0964, -0.0133]],\n",
      "\n",
      "         [[-0.0120,  0.0402],\n",
      "          [ 0.0536,  0.0630],\n",
      "          [ 0.0578,  0.0300],\n",
      "          [-0.0002, -0.0895],\n",
      "          [ 0.0079,  0.0557],\n",
      "          [-0.0040, -0.0034]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Rotated key =  tensor([[[[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "RIGHT BEFORE ATTN :- \n",
      "\n",
      "Q =  tensor([[[[-0.0113, -0.0217],\n",
      "          [ 0.0164, -0.0711],\n",
      "          [ 0.0026, -0.0137],\n",
      "          [-0.0110, -0.0263],\n",
      "          [ 0.0261, -0.0399],\n",
      "          [ 0.0448,  0.0577]],\n",
      "\n",
      "         [[-0.0369, -0.0231],\n",
      "          [ 0.0025, -0.0622],\n",
      "          [ 0.0677,  0.0699],\n",
      "          [ 0.0649, -0.0412],\n",
      "          [ 0.0105, -0.0802],\n",
      "          [-0.0488, -0.0284]],\n",
      "\n",
      "         [[ 0.0018,  0.0096],\n",
      "          [-0.0681, -0.0234],\n",
      "          [-0.0098, -0.0375],\n",
      "          [-0.0772, -0.0972],\n",
      "          [ 0.0373,  0.0051],\n",
      "          [ 0.0964, -0.0133]],\n",
      "\n",
      "         [[-0.0120,  0.0402],\n",
      "          [ 0.0536,  0.0630],\n",
      "          [ 0.0578,  0.0300],\n",
      "          [-0.0002, -0.0895],\n",
      "          [ 0.0079,  0.0557],\n",
      "          [-0.0040, -0.0034]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "K =  tensor([[[[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V =  tensor([[[[-0.0372, -0.0752],\n",
      "          [-0.0334, -0.1026],\n",
      "          [-0.0387,  0.0184],\n",
      "          [-0.0112, -0.0671],\n",
      "          [-0.0131,  0.0943],\n",
      "          [ 0.1154,  0.0390]],\n",
      "\n",
      "         [[-0.0372, -0.0752],\n",
      "          [-0.0334, -0.1026],\n",
      "          [-0.0387,  0.0184],\n",
      "          [-0.0112, -0.0671],\n",
      "          [-0.0131,  0.0943],\n",
      "          [ 0.1154,  0.0390]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [ 0.0050, -0.0126],\n",
      "          [ 0.0497, -0.0733],\n",
      "          [-0.0189, -0.0172],\n",
      "          [-0.0999, -0.0100],\n",
      "          [ 0.0345, -0.0383]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [ 0.0050, -0.0126],\n",
      "          [ 0.0497, -0.0733],\n",
      "          [-0.0189, -0.0172],\n",
      "          [-0.0999, -0.0100],\n",
      "          [ 0.0345, -0.0383]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "True\n",
      "tensor([[[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]]]])\n",
      "ATTN OUTPUT =  tensor([[[[-0.0372, -0.0752],\n",
      "          [-0.0353, -0.0889],\n",
      "          [-0.0364, -0.0531],\n",
      "          [-0.0278, -0.0505],\n",
      "          [-0.0210,  0.0153],\n",
      "          [ 0.0301,  0.0219]],\n",
      "\n",
      "         [[-0.0372, -0.0752],\n",
      "          [-0.0353, -0.0889],\n",
      "          [-0.0364, -0.0529],\n",
      "          [-0.0278, -0.0503],\n",
      "          [-0.0210,  0.0154],\n",
      "          [ 0.0306,  0.0221]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [-0.0187, -0.0011],\n",
      "          [ 0.0041, -0.0252],\n",
      "          [ 0.0120, -0.0344],\n",
      "          [-0.0230, -0.0335],\n",
      "          [-0.0279, -0.0219]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [-0.0187, -0.0011],\n",
      "          [ 0.0041, -0.0252],\n",
      "          [ 0.0120, -0.0344],\n",
      "          [-0.0230, -0.0335],\n",
      "          [-0.0281, -0.0218]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "SA OUTPUT =  tensor([[[-5.4631e-04, -4.2851e-04, -2.7580e-03,  3.4945e-04,  1.8132e-03,\n",
      "          -9.3882e-05, -1.9177e-03, -1.4553e-05],\n",
      "         [ 4.6210e-04, -6.6375e-04, -3.0637e-03,  4.6621e-04,  3.0429e-03,\n",
      "          -2.9930e-04,  3.0276e-04, -2.4526e-03],\n",
      "         [ 1.6153e-03, -2.3367e-04, -1.4735e-03,  5.7002e-04,  2.9275e-03,\n",
      "          -7.5637e-04,  2.8188e-03, -3.0160e-03],\n",
      "         [ 2.0543e-03, -1.8132e-04, -1.3591e-03, -6.8881e-05,  3.3867e-03,\n",
      "          -1.0794e-03,  3.4974e-03, -3.6740e-03],\n",
      "         [ 8.1219e-04,  8.0704e-04,  7.4197e-04, -1.1923e-03,  6.8060e-04,\n",
      "          -1.2882e-03,  3.6161e-04,  1.4475e-03],\n",
      "         [-1.1690e-04,  7.3303e-04,  4.5419e-04, -3.7673e-03,  3.0093e-04,\n",
      "          -1.3759e-03, -2.1586e-03,  2.1960e-03]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "ATTN DONE\n",
      "\n",
      "residual + hidden_states :-  tensor([[[-0.0079, -0.0258,  0.0040,  0.0116,  0.0333,  0.0373,  0.0146,\n",
      "          -0.0181],\n",
      "         [-0.0126,  0.0211,  0.0195,  0.0529,  0.0132,  0.0360,  0.0036,\n",
      "          -0.0161],\n",
      "         [-0.0293,  0.0207, -0.0229,  0.0271, -0.0118, -0.0251,  0.0378,\n",
      "           0.0220],\n",
      "         [-0.0117, -0.0132,  0.0125,  0.0085, -0.0016, -0.0002, -0.0036,\n",
      "           0.0047],\n",
      "         [ 0.0384, -0.0118,  0.0074, -0.0021,  0.0192, -0.0385, -0.0125,\n",
      "           0.0218],\n",
      "         [-0.0162,  0.0156,  0.0074, -0.0136, -0.0115, -0.0137,  0.0155,\n",
      "           0.0388]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Post attention hidden_states :-  tensor([[[-0.3540, -1.1556,  0.1783,  0.5175,  1.4878,  1.6687,  0.6509,\n",
      "          -0.8112],\n",
      "         [-0.4757,  0.7970,  0.7350,  1.9997,  0.4985,  1.3595,  0.1342,\n",
      "          -0.6091],\n",
      "         [-1.1389,  0.8025, -0.8887,  1.0517, -0.4577, -0.9731,  1.4679,\n",
      "           0.8553],\n",
      "         [-1.2954, -1.4519,  1.3833,  0.9339, -0.1723, -0.0233, -0.3952,\n",
      "           0.5166],\n",
      "         [ 1.6706, -0.5140,  0.3236, -0.0921,  0.8347, -1.6713, -0.5417,\n",
      "           0.9473],\n",
      "         [-0.8497,  0.8217,  0.3899, -0.7164, -0.6033, -0.7204,  0.8158,\n",
      "           2.0416]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "MLP output :-  tensor([[[-1.2187e-04,  1.0936e-04,  5.0067e-05,  5.7114e-06,  3.9269e-05,\n",
      "           6.6643e-05, -2.4155e-06, -3.4821e-06],\n",
      "         [ 7.0467e-06,  1.1566e-05,  2.6548e-05, -8.7865e-05,  2.4080e-05,\n",
      "          -4.2541e-05,  1.0945e-05, -1.3540e-05],\n",
      "         [-5.2288e-05, -1.5715e-05, -7.5799e-05,  1.3520e-05, -7.0849e-05,\n",
      "           5.1186e-05, -5.5571e-05, -4.9581e-05],\n",
      "         [-1.6200e-05,  1.7879e-05,  9.1819e-06, -4.7022e-05, -1.8474e-05,\n",
      "          -2.2538e-05, -2.9023e-05, -2.0955e-05],\n",
      "         [ 1.4794e-05,  1.4537e-05,  1.0603e-04, -2.4205e-05, -6.2248e-06,\n",
      "           6.8486e-05,  7.7879e-05, -1.6004e-06],\n",
      "         [-1.0246e-05,  1.9793e-05,  7.4387e-06, -3.5195e-06, -3.0005e-05,\n",
      "          -5.9967e-05,  2.5739e-05, -1.7977e-05]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "OUTPUTS =  (tensor([[[-0.0080, -0.0257,  0.0040,  0.0116,  0.0333,  0.0374,  0.0146,\n",
      "          -0.0181],\n",
      "         [-0.0126,  0.0211,  0.0195,  0.0529,  0.0132,  0.0360,  0.0036,\n",
      "          -0.0161],\n",
      "         [-0.0294,  0.0207, -0.0230,  0.0271, -0.0119, -0.0250,  0.0377,\n",
      "           0.0220],\n",
      "         [-0.0118, -0.0131,  0.0125,  0.0084, -0.0016, -0.0002, -0.0036,\n",
      "           0.0047],\n",
      "         [ 0.0385, -0.0118,  0.0076, -0.0021,  0.0192, -0.0384, -0.0124,\n",
      "           0.0218],\n",
      "         [-0.0162,  0.0156,  0.0074, -0.0136, -0.0115, -0.0138,  0.0155,\n",
      "           0.0388]]], grad_fn=<AddBackward0>),)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = tinymistral(**tokenized_src_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, MistralForCausalLM\n",
    "\n",
    "# model = MistralForCausalLM.from_pretrained(\"openaccess-ai-collective/tiny-mistral\")\n",
    "\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")\n",
    "\n",
    "# prompt = \"Hey, are you conscious? Can you talk to me?\"\n",
    "# inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "# # Generate\n",
    "# generate_ids = model.generate(inputs.input_ids, max_length=30)\n",
    "# tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
