{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import set_seed\n",
    "import torch\n",
    "SEED = 6\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralConfig {\n",
       "  \"_name_or_path\": \"./tiny-mistral\",\n",
       "  \"architectures\": [\n",
       "    \"MistralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"dropout_p\": 0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 8,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mistral\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 1,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"sliding_window\": 3,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.38.0.dev0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, MistralConfig\n",
    "\n",
    "\n",
    "mistral_config = MistralConfig.from_pretrained(\"openaccess-ai-collective/tiny-mistral\", num_hidden_layers = 1, use_cache = False, hidden_size = 8, num_attention_heads = 4, \n",
    "                                           output_hidden_states=True,  num_key_value_heads = 2, past_key_values = True, intermediate_size = 8, sliding_window = 3, dropout_p = 0)\n",
    "\n",
    "\n",
    "mistral_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "tinymistral = AutoModel.from_config(mistral_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "src_sent = \"hi how are you doing\"\n",
    "\n",
    "mistal_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict = mistal_tokenizer.encode_plus(src_sent, return_tensors='pt')\n",
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict = mistal_tokenizer.encode_plus(src_sent, return_tensors='pt')\n",
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 12014,   910,   460,   368,  2548]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized = tokenized_src_dict[\"input_ids\"]\n",
    "src_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hi how are you doing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistal_tokenizer.decode(*src_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True,  True,  True,  True],\n",
       "        [False, False,  True,  True,  True,  True],\n",
       "        [False, False, False,  True,  True,  True],\n",
       "        [ True, False, False, False,  True,  True],\n",
       "        [ True,  True, False, False, False,  True],\n",
       "        [ True,  True,  True, False, False, False]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = src_tokenized.shape[1]\n",
    "sliding_window_len = 3\n",
    "\n",
    "sliding_window_mask = (torch.triu(torch.ones(seq_length, seq_length), diagonal=1)).bool()\n",
    "\n",
    "# print(sliding_window_mask)\n",
    "\n",
    "for i in range(sliding_window_mask.shape[0]-1, -1, -1):\n",
    "\n",
    "    li = i - sliding_window_len + 1\n",
    "\n",
    "    if li > 0:\n",
    "\n",
    "        sliding_window_mask[i][0:li] = True\n",
    "\n",
    "sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 6, 6]),\n",
       " tensor([[[[False,  True,  True,  True,  True,  True],\n",
       "           [False, False,  True,  True,  True,  True],\n",
       "           [False, False, False,  True,  True,  True],\n",
       "           [ True, False, False, False,  True,  True],\n",
       "           [ True,  True, False, False, False,  True],\n",
       "           [ True,  True,  True, False, False, False]]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask.shape, sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[[[False,  True,  True,  True,  True,  True],\n",
      "          [False, False,  True,  True,  True,  True],\n",
      "          [False, False, False,  True,  True,  True],\n",
      "          [ True, False, False, False,  True,  True],\n",
      "          [ True,  True, False, False, False,  True],\n",
      "          [ True,  True,  True, False, False, False]]]]),\n",
      " 'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "tokenized_src_dict[\"attention_mask\"] = sliding_window_mask\n",
    "\n",
    "pprint(tokenized_src_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sdpa\n",
      "\n",
      "###########################################################################\n",
      "LLAMA DECODER FWD START\n",
      "\n",
      "Attention mask =  tensor([[[[-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38]]]])\n",
      "\n",
      "Input (hidden states) =  tensor([[[-0.0074, -0.0254,  0.0067,  0.0112,  0.0315,  0.0374,  0.0165,\n",
      "          -0.0181],\n",
      "         [-0.0131,  0.0218,  0.0225,  0.0525,  0.0102,  0.0363,  0.0032,\n",
      "          -0.0137],\n",
      "         [-0.0309,  0.0209, -0.0214,  0.0265, -0.0147, -0.0243,  0.0350,\n",
      "           0.0250],\n",
      "         [-0.0138, -0.0130,  0.0139,  0.0085, -0.0049,  0.0009, -0.0071,\n",
      "           0.0084],\n",
      "         [ 0.0376, -0.0126,  0.0067, -0.0009,  0.0185, -0.0372, -0.0128,\n",
      "           0.0204],\n",
      "         [-0.0160,  0.0149,  0.0070, -0.0099, -0.0118, -0.0123,  0.0177,\n",
      "           0.0366]]], grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "LayerNorm(hidden states) =  tensor([[[-0.3321, -1.1450,  0.3039,  0.5057,  1.4174,  1.6856,  0.7422,\n",
      "          -0.8167],\n",
      "         [-0.4934,  0.8224,  0.8510,  1.9829,  0.3837,  1.3713,  0.1228,\n",
      "          -0.5167],\n",
      "         [-1.2029,  0.8125, -0.8324,  1.0307, -0.5720, -0.9447,  1.3599,\n",
      "           0.9734],\n",
      "         [-1.3384, -1.2590,  1.3482,  0.8278, -0.4802,  0.0843, -0.6869,\n",
      "           0.8108],\n",
      "         [ 1.6819, -0.5647,  0.2996, -0.0414,  0.8280, -1.6612, -0.5732,\n",
      "           0.9095],\n",
      "         [-0.8816,  0.8184,  0.3826, -0.5416, -0.6470, -0.6772,  0.9711,\n",
      "           2.0128]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "position_ids =  tensor([[0, 1, 2, 3, 4, 5]])\n",
      "bsz, query_len  =  1 6\n",
      "\n",
      "query =  tensor([[[-0.0113, -0.0217, -0.0369, -0.0231,  0.0018,  0.0096, -0.0120,\n",
      "           0.0402],\n",
      "         [-0.0510, -0.0522, -0.0510, -0.0357, -0.0565,  0.0447,  0.0820,\n",
      "          -0.0111],\n",
      "         [-0.0135,  0.0034,  0.0354, -0.0907, -0.0300,  0.0246,  0.0032,\n",
      "          -0.0650],\n",
      "         [ 0.0072,  0.0276, -0.0701,  0.0316,  0.0627,  0.1072, -0.0125,\n",
      "           0.0886],\n",
      "         [ 0.0131,  0.0458,  0.0538,  0.0604, -0.0282,  0.0249, -0.0474,\n",
      "          -0.0304],\n",
      "         [-0.0426,  0.0593,  0.0134, -0.0548,  0.0401,  0.0886,  0.0021,\n",
      "          -0.0048]]], grad_fn=<UnsafeViewBackward0>)\n",
      "key =  tensor([[[-0.0682,  0.0924, -0.0166,  0.0247],\n",
      "         [-0.0963, -0.0072, -0.0289,  0.0196],\n",
      "         [-0.0226, -0.1110, -0.0446,  0.0053],\n",
      "         [ 0.0608, -0.0750, -0.0111, -0.0111],\n",
      "         [ 0.0157,  0.0671,  0.0796, -0.0588],\n",
      "         [ 0.0609, -0.1770, -0.0375,  0.0568]]], grad_fn=<UnsafeViewBackward0>)\n",
      "value =  tensor([[[-0.0372, -0.0752, -0.0424,  0.0104],\n",
      "         [-0.0334, -0.1026,  0.0050, -0.0126],\n",
      "         [-0.0387,  0.0184,  0.0497, -0.0733],\n",
      "         [-0.0112, -0.0671, -0.0189, -0.0172],\n",
      "         [-0.0131,  0.0943, -0.0999, -0.0100],\n",
      "         [ 0.1154,  0.0390,  0.0345, -0.0383]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "torch.Size([1, 6, 8]) torch.Size([1, 6, 4]) torch.Size([1, 6, 4])\n",
      "\n",
      "torch.Size([1, 4, 6, 2]) torch.Size([1, 2, 6, 2]) torch.Size([1, 2, 6, 2])\n",
      "\n",
      "kv_seq_len =  6\n",
      "\n",
      "max_position_embeddings =  32768\n",
      "Cos =  tensor([[ 1.0000,  1.0000],\n",
      "        [ 0.5403,  0.5403],\n",
      "        [-0.4161, -0.4161],\n",
      "        [-0.9900, -0.9900],\n",
      "        [-0.6536, -0.6536],\n",
      "        [ 0.2837,  0.2837]])\n",
      "\n",
      "Sin =  tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.8415,  0.8415],\n",
      "        [ 0.9093,  0.9093],\n",
      "        [ 0.1411,  0.1411],\n",
      "        [-0.7568, -0.7568],\n",
      "        [-0.9589, -0.9589]])\n",
      "\n",
      "Rotated query =  tensor([[[[-0.0113, -0.0217],\n",
      "          [ 0.0164, -0.0711],\n",
      "          [ 0.0026, -0.0137],\n",
      "          [-0.0110, -0.0263],\n",
      "          [ 0.0261, -0.0399],\n",
      "          [ 0.0448,  0.0577]],\n",
      "\n",
      "         [[-0.0369, -0.0231],\n",
      "          [ 0.0025, -0.0622],\n",
      "          [ 0.0677,  0.0699],\n",
      "          [ 0.0649, -0.0412],\n",
      "          [ 0.0105, -0.0802],\n",
      "          [-0.0488, -0.0284]],\n",
      "\n",
      "         [[ 0.0018,  0.0096],\n",
      "          [-0.0681, -0.0234],\n",
      "          [-0.0098, -0.0375],\n",
      "          [-0.0772, -0.0972],\n",
      "          [ 0.0373,  0.0051],\n",
      "          [ 0.0964, -0.0133]],\n",
      "\n",
      "         [[-0.0120,  0.0402],\n",
      "          [ 0.0536,  0.0630],\n",
      "          [ 0.0578,  0.0300],\n",
      "          [-0.0002, -0.0895],\n",
      "          [ 0.0079,  0.0557],\n",
      "          [-0.0040, -0.0034]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Rotated key =  tensor([[[[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "RIGHT BEFORE ATTN :- \n",
      "\n",
      "Q =  tensor([[[[-0.0113, -0.0217],\n",
      "          [ 0.0164, -0.0711],\n",
      "          [ 0.0026, -0.0137],\n",
      "          [-0.0110, -0.0263],\n",
      "          [ 0.0261, -0.0399],\n",
      "          [ 0.0448,  0.0577]],\n",
      "\n",
      "         [[-0.0369, -0.0231],\n",
      "          [ 0.0025, -0.0622],\n",
      "          [ 0.0677,  0.0699],\n",
      "          [ 0.0649, -0.0412],\n",
      "          [ 0.0105, -0.0802],\n",
      "          [-0.0488, -0.0284]],\n",
      "\n",
      "         [[ 0.0018,  0.0096],\n",
      "          [-0.0681, -0.0234],\n",
      "          [-0.0098, -0.0375],\n",
      "          [-0.0772, -0.0972],\n",
      "          [ 0.0373,  0.0051],\n",
      "          [ 0.0964, -0.0133]],\n",
      "\n",
      "         [[-0.0120,  0.0402],\n",
      "          [ 0.0536,  0.0630],\n",
      "          [ 0.0578,  0.0300],\n",
      "          [-0.0002, -0.0895],\n",
      "          [ 0.0079,  0.0557],\n",
      "          [-0.0040, -0.0034]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "K =  tensor([[[[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0682,  0.0924],\n",
      "          [-0.0460, -0.0850],\n",
      "          [ 0.1103,  0.0256],\n",
      "          [-0.0496,  0.0828],\n",
      "          [ 0.0406, -0.0557],\n",
      "          [-0.1524, -0.1085]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]],\n",
      "\n",
      "         [[-0.0166,  0.0247],\n",
      "          [-0.0321, -0.0137],\n",
      "          [ 0.0137, -0.0427],\n",
      "          [ 0.0125,  0.0094],\n",
      "          [-0.0966, -0.0218],\n",
      "          [ 0.0438,  0.0521]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V =  tensor([[[[-0.0372, -0.0752],\n",
      "          [-0.0334, -0.1026],\n",
      "          [-0.0387,  0.0184],\n",
      "          [-0.0112, -0.0671],\n",
      "          [-0.0131,  0.0943],\n",
      "          [ 0.1154,  0.0390]],\n",
      "\n",
      "         [[-0.0372, -0.0752],\n",
      "          [-0.0334, -0.1026],\n",
      "          [-0.0387,  0.0184],\n",
      "          [-0.0112, -0.0671],\n",
      "          [-0.0131,  0.0943],\n",
      "          [ 0.1154,  0.0390]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [ 0.0050, -0.0126],\n",
      "          [ 0.0497, -0.0733],\n",
      "          [-0.0189, -0.0172],\n",
      "          [-0.0999, -0.0100],\n",
      "          [ 0.0345, -0.0383]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [ 0.0050, -0.0126],\n",
      "          [ 0.0497, -0.0733],\n",
      "          [-0.0189, -0.0172],\n",
      "          [-0.0999, -0.0100],\n",
      "          [ 0.0345, -0.0383]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "True\n",
      "tensor([[[[-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "            0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38]]]])\n",
      "ATTN OUTPUT =  tensor([[[[ 0.0039, -0.0036],\n",
      "          [ 0.0132,  0.0213],\n",
      "          [ 0.0304,  0.0221],\n",
      "          [ 0.0218,  0.0195],\n",
      "          [ 0.0150, -0.0462],\n",
      "          [-0.0364, -0.0530]],\n",
      "\n",
      "         [[ 0.0039, -0.0036],\n",
      "          [ 0.0132,  0.0213],\n",
      "          [ 0.0300,  0.0219],\n",
      "          [ 0.0216,  0.0196],\n",
      "          [ 0.0151, -0.0461],\n",
      "          [-0.0364, -0.0533]],\n",
      "\n",
      "         [[-0.0059, -0.0303],\n",
      "          [-0.0088, -0.0347],\n",
      "          [-0.0282, -0.0218],\n",
      "          [-0.0362, -0.0126],\n",
      "          [-0.0009, -0.0135],\n",
      "          [ 0.0041, -0.0252]],\n",
      "\n",
      "         [[-0.0059, -0.0303],\n",
      "          [-0.0085, -0.0347],\n",
      "          [-0.0279, -0.0219],\n",
      "          [-0.0360, -0.0126],\n",
      "          [-0.0010, -0.0135],\n",
      "          [ 0.0041, -0.0252]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "SA OUTPUT =  tensor([[[ 1.0109e-03,  3.8513e-04, -6.6767e-05, -2.0053e-03,  1.5735e-03,\n",
      "          -1.2705e-03,  7.7597e-04, -4.9062e-04],\n",
      "         [ 8.9381e-04,  7.0837e-04,  7.6528e-04, -2.6425e-03,  8.8182e-04,\n",
      "          -1.4674e-03,  3.3745e-04,  6.0953e-04],\n",
      "         [-1.1649e-04,  7.4530e-04,  4.5455e-04, -3.7672e-03,  2.8868e-04,\n",
      "          -1.3996e-03, -2.1439e-03,  2.1899e-03],\n",
      "         [-5.6876e-04,  6.9552e-04,  3.4460e-04, -3.1338e-03, -1.7854e-04,\n",
      "          -1.0727e-03, -2.8525e-03,  2.8685e-03],\n",
      "         [ 6.8582e-04, -3.0296e-04, -1.7586e-03, -2.0204e-03,  2.5383e-03,\n",
      "          -8.5557e-04,  2.9501e-04, -2.2604e-03],\n",
      "         [ 1.6329e-03, -2.4369e-04, -1.4876e-03,  5.4666e-04,  2.9363e-03,\n",
      "          -7.6351e-04,  2.8281e-03, -3.0246e-03]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "ATTN DONE\n",
      "\n",
      "residual + hidden_states :-  tensor([[[-0.0064, -0.0250,  0.0067,  0.0092,  0.0330,  0.0361,  0.0172,\n",
      "          -0.0186],\n",
      "         [-0.0122,  0.0225,  0.0233,  0.0498,  0.0110,  0.0348,  0.0036,\n",
      "          -0.0131],\n",
      "         [-0.0311,  0.0216, -0.0210,  0.0227, -0.0144, -0.0257,  0.0328,\n",
      "           0.0272],\n",
      "         [-0.0144, -0.0123,  0.0142,  0.0054, -0.0051, -0.0002, -0.0099,\n",
      "           0.0112],\n",
      "         [ 0.0383, -0.0129,  0.0049, -0.0029,  0.0211, -0.0380, -0.0125,\n",
      "           0.0181],\n",
      "         [-0.0144,  0.0147,  0.0055, -0.0093, -0.0088, -0.0131,  0.0205,\n",
      "           0.0336]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Post attention hidden_states :-  tensor([[[-0.2874, -1.1310,  0.3018,  0.4165,  1.4926,  1.6331,  0.7795,\n",
      "          -0.8413],\n",
      "         [-0.4736,  0.8750,  0.9067,  1.9404,  0.4297,  1.3560,  0.1397,\n",
      "          -0.5087],\n",
      "         [-1.2232,  0.8524, -0.8253,  0.8958, -0.5681, -1.0122,  1.2932,\n",
      "           1.0724],\n",
      "         [-1.3393, -1.1451,  1.3278,  0.5032, -0.4781, -0.0190, -0.9262,\n",
      "           1.0468],\n",
      "         [ 1.6879, -0.5699,  0.2178, -0.1298,  0.9279, -1.6750, -0.5520,\n",
      "           0.7969],\n",
      "         [-0.8289,  0.8427,  0.3149, -0.5355, -0.5083, -0.7528,  1.1792,\n",
      "           1.9330]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "MLP output :-  tensor([[[-1.1575e-04,  9.8689e-05,  4.5004e-05,  1.1478e-05,  3.5661e-05,\n",
      "           6.2797e-05,  3.3365e-06, -4.9717e-06],\n",
      "         [ 1.3174e-05, -1.5803e-05,  5.6374e-06, -8.7172e-05,  1.4859e-05,\n",
      "          -5.1375e-05,  3.1793e-06, -2.3722e-05],\n",
      "         [-4.1159e-05, -2.8844e-05, -7.9101e-05,  2.8782e-05, -6.7190e-05,\n",
      "           6.9239e-05, -5.9853e-05, -4.1256e-05],\n",
      "         [-1.0104e-04,  8.0418e-05,  1.7472e-05, -4.9385e-05,  1.1550e-05,\n",
      "          -2.8566e-05, -3.0777e-05, -3.1977e-05],\n",
      "         [ 1.5415e-06,  1.6837e-05,  9.3766e-05, -2.0141e-05, -5.2678e-06,\n",
      "           7.3701e-05,  7.0558e-05, -5.3240e-06],\n",
      "         [-1.0567e-05, -1.1134e-05, -2.1993e-05,  1.4952e-05, -4.7793e-05,\n",
      "          -1.8826e-05,  4.9785e-06, -2.7267e-05]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "OUTPUTS =  (tensor([[[-0.0065, -0.0249,  0.0067,  0.0092,  0.0331,  0.0362,  0.0173,\n",
      "          -0.0186],\n",
      "         [-0.0122,  0.0225,  0.0233,  0.0498,  0.0111,  0.0348,  0.0036,\n",
      "          -0.0131],\n",
      "         [-0.0311,  0.0216, -0.0210,  0.0228, -0.0145, -0.0256,  0.0328,\n",
      "           0.0272],\n",
      "         [-0.0145, -0.0122,  0.0143,  0.0053, -0.0051, -0.0002, -0.0100,\n",
      "           0.0112],\n",
      "         [ 0.0383, -0.0129,  0.0050, -0.0030,  0.0211, -0.0380, -0.0125,\n",
      "           0.0181],\n",
      "         [-0.0144,  0.0146,  0.0055, -0.0093, -0.0089, -0.0131,  0.0205,\n",
      "           0.0336]]], grad_fn=<AddBackward0>),)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = tinymistral(**tokenized_src_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **SLIDING WINDOW ATTENTION** and **GROUPED-QUERY ATTENTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_config.num_key_value_heads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rep =  2\n"
     ]
    }
   ],
   "source": [
    "# head_dim = 4\n",
    "# num_heads = 1\n",
    "# seq_len = 4\n",
    "\n",
    "embed_dim = 8\n",
    "\n",
    "num_heads = 4\n",
    "\n",
    "n_heads_q = num_heads\n",
    "\n",
    "n_kv_heads = 2\n",
    "\n",
    "seq_len = 6\n",
    "\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "n_rep = n_heads_q//n_kv_heads\n",
    "print(\"n_rep = \", n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = tinymistral.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def look_up_table(sentence, vocab_embeds, embedding):\n",
    "\n",
    "    for i in range(sentence.size(0)):\n",
    "        for j in range(sentence.size(1)):\n",
    "            \n",
    "            # Get the index for the current word token index in the sequence\n",
    "            word_index = sentence[i, j].item()\n",
    "\n",
    "            if word_index < 0 or word_index >= vocab_embeds.size(0):\n",
    "                raise ValueError(f\"Invalid word index: {word_index}\")\n",
    "\n",
    "            # Lookup the corresponding embedding vector for the word\n",
    "            embedding[i, j, :] = vocab_embeds[word_index, :]\n",
    "\n",
    "            print(f\"Word index: {word_index}, Embedding: {vocab_embeds[word_index, :]}\")\n",
    "    print()\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence embedding\n",
      "Word index: 1, Embedding: tensor([-0.0074, -0.0254,  0.0067,  0.0112,  0.0315,  0.0374,  0.0165, -0.0181])\n",
      "Word index: 12014, Embedding: tensor([-0.0131,  0.0218,  0.0225,  0.0525,  0.0102,  0.0363,  0.0032, -0.0137])\n",
      "Word index: 910, Embedding: tensor([-0.0309,  0.0209, -0.0214,  0.0265, -0.0147, -0.0243,  0.0350,  0.0250])\n",
      "Word index: 460, Embedding: tensor([-0.0138, -0.0130,  0.0139,  0.0085, -0.0049,  0.0009, -0.0071,  0.0084])\n",
      "Word index: 368, Embedding: tensor([ 0.0376, -0.0126,  0.0067, -0.0009,  0.0185, -0.0372, -0.0128,  0.0204])\n",
      "Word index: 2548, Embedding: tensor([-0.0160,  0.0149,  0.0070, -0.0099, -0.0118, -0.0123,  0.0177,  0.0366])\n",
      "\n",
      "torch.Size([1, 6, 8])\n",
      "Source embeddings : \n",
      "\n",
      "tensor([[[-0.0074, -0.0254,  0.0067,  0.0112,  0.0315,  0.0374,  0.0165,\n",
      "          -0.0181],\n",
      "         [-0.0131,  0.0218,  0.0225,  0.0525,  0.0102,  0.0363,  0.0032,\n",
      "          -0.0137],\n",
      "         [-0.0309,  0.0209, -0.0214,  0.0265, -0.0147, -0.0243,  0.0350,\n",
      "           0.0250],\n",
      "         [-0.0138, -0.0130,  0.0139,  0.0085, -0.0049,  0.0009, -0.0071,\n",
      "           0.0084],\n",
      "         [ 0.0376, -0.0126,  0.0067, -0.0009,  0.0185, -0.0372, -0.0128,\n",
      "           0.0204],\n",
      "         [-0.0160,  0.0149,  0.0070, -0.0099, -0.0118, -0.0123,  0.0177,\n",
      "           0.0366]]])\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_outputs(src_tokens, state_dict, d_model):\n",
    "\n",
    "    src_vocab_embeds = state_dict[\"embed_tokens.weight\"]\n",
    "\n",
    "    src_embedding = torch.zeros(src_tokens.size(0), src_tokens.size(1), d_model)\n",
    "    print(\"Source sentence embedding\")\n",
    "    src_embedding =  look_up_table(src_tokens, src_vocab_embeds, src_embedding)\n",
    "    print(src_embedding.shape)\n",
    "\n",
    "\n",
    "    print(\"Source embeddings : \\n\")\n",
    "    print(src_embedding)\n",
    "\n",
    "    return src_embedding\n",
    "\n",
    "\n",
    "input_embeddings = get_embedding_outputs(src_tokenized, state_dict, d_model = embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_layernorm(hidden_states, wt, variance_epsilon = 1e-05):\n",
    "\n",
    "    dtype =  hidden_states.dtype\n",
    "    hidden_states = hidden_states.to(torch.float32)\n",
    "    variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "    hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
    "    op = wt * hidden_states\n",
    "    return op.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3321, -1.1450,  0.3039,  0.5057,  1.4174,  1.6856,  0.7422,\n",
       "          -0.8167],\n",
       "         [-0.4934,  0.8224,  0.8510,  1.9829,  0.3837,  1.3713,  0.1228,\n",
       "          -0.5167],\n",
       "         [-1.2029,  0.8125, -0.8324,  1.0307, -0.5720, -0.9447,  1.3599,\n",
       "           0.9734],\n",
       "         [-1.3384, -1.2590,  1.3482,  0.8278, -0.4802,  0.0843, -0.6869,\n",
       "           0.8108],\n",
       "         [ 1.6819, -0.5647,  0.2996, -0.0414,  0.8280, -1.6612, -0.5732,\n",
       "           0.9095],\n",
       "         [-0.8816,  0.8184,  0.3826, -0.5416, -0.6470, -0.6772,  0.9711,\n",
       "           2.0128]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = apply_layernorm(input_embeddings, state_dict[\"layers.0.input_layernorm.weight\"], variance_epsilon = 1e-05)\n",
    "\n",
    "hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embed_tokens.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.mlp.down_proj.weight', 'layers.0.input_layernorm.weight', 'layers.0.post_attention_layernorm.weight', 'norm.weight'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qkv(hidden_state ,Wq, Wk, Wv):\n",
    "\n",
    "\n",
    "    q_matmul = hidden_state@Wq.T\n",
    "    k_matmul = hidden_state@Wk.T\n",
    "    v_matmul = hidden_state@Wv.T\n",
    "\n",
    "    return q_matmul, k_matmul, v_matmul\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = state_dict[\"layers.0.self_attn.q_proj.weight\"]\n",
    "Wk = state_dict[\"layers.0.self_attn.k_proj.weight\"]\n",
    "Wv = state_dict[\"layers.0.self_attn.v_proj.weight\"]\n",
    "query, key, value = get_qkv(hidden_state ,Wq, Wk, Wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-0.0113, -0.0217, -0.0369, -0.0231,  0.0018,  0.0096, -0.0120,\n",
       "            0.0402],\n",
       "          [-0.0510, -0.0522, -0.0510, -0.0357, -0.0565,  0.0447,  0.0820,\n",
       "           -0.0111],\n",
       "          [-0.0135,  0.0034,  0.0354, -0.0907, -0.0300,  0.0246,  0.0032,\n",
       "           -0.0650],\n",
       "          [ 0.0072,  0.0276, -0.0701,  0.0316,  0.0627,  0.1072, -0.0125,\n",
       "            0.0886],\n",
       "          [ 0.0131,  0.0458,  0.0538,  0.0604, -0.0282,  0.0249, -0.0474,\n",
       "           -0.0304],\n",
       "          [-0.0426,  0.0593,  0.0134, -0.0548,  0.0401,  0.0886,  0.0021,\n",
       "           -0.0048]]]),\n",
       " tensor([[[-0.0682,  0.0924, -0.0166,  0.0247],\n",
       "          [-0.0963, -0.0072, -0.0289,  0.0196],\n",
       "          [-0.0226, -0.1110, -0.0446,  0.0053],\n",
       "          [ 0.0608, -0.0750, -0.0111, -0.0111],\n",
       "          [ 0.0157,  0.0671,  0.0796, -0.0588],\n",
       "          [ 0.0609, -0.1770, -0.0375,  0.0568]]]),\n",
       " tensor([[[-0.0372, -0.0752, -0.0424,  0.0104],\n",
       "          [-0.0334, -0.1026,  0.0050, -0.0126],\n",
       "          [-0.0387,  0.0184,  0.0497, -0.0733],\n",
       "          [-0.0112, -0.0671, -0.0189, -0.0172],\n",
       "          [-0.0131,  0.0943, -0.0999, -0.0100],\n",
       "          [ 0.1154,  0.0390,  0.0345, -0.0383]]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query, key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sin_cos(dim, seq_len, max_seq_len, base = 10000):\n",
    "\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
    "\n",
    "    t = torch.arange(max_seq_len, dtype=torch.int64).type_as(inv_freq)\n",
    "\n",
    "    freqs = torch.outer(t, inv_freq)\n",
    "    \n",
    "    # Uses a different permutation in order to obtain the same calculation\n",
    "    emb = torch.cat((freqs, freqs), dim=-1)    \n",
    "\n",
    "    return  emb.cos()[:seq_len], emb.sin()[:seq_len]\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "\n",
    "    # print(x1.shape, x2.shape)\n",
    "    # x1 = x[ : , : x.shape[-1] // 2]\n",
    "    # x2 = x[ : , x.shape[-1] // 2 :]\n",
    "\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=1):\n",
    "\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    # print(\"HALF ROT SHAPES = \")\n",
    "    # print((rotate_half(q).shape,   sin.shape))\n",
    "    # print((rotate_half(k).shape , sin.shape))\n",
    "\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6, 8]), torch.Size([1, 6, 4]), torch.Size([1, 6, 4]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, q_len, _ = query.shape\n",
    "\n",
    "query = query.view(bsz, q_len, n_heads_q, head_dim).transpose(1, 2)\n",
    "key = key.view(bsz, q_len, n_kv_heads, head_dim).transpose(1, 2)\n",
    "value = value.view(bsz, q_len, n_kv_heads, head_dim).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 6, 2]), torch.Size([1, 2, 6, 2]), torch.Size([1, 2, 6, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Rope(query, key, head_dim, seq_len,  num_heads):\n",
    "\n",
    "    cos, sin = get_sin_cos(dim = head_dim, seq_len = seq_len, max_seq_len = 2048, base = 10000)\n",
    "\n",
    "    cos = cos.unsqueeze(0)\n",
    "    sin = sin.unsqueeze(0)\n",
    "\n",
    "    q_rotated, k_rotated = apply_rotary_pos_emb(query, key, cos, sin, unsqueeze_dim=1)\n",
    "\n",
    "    return q_rotated, k_rotated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_rotated, key_rotated = get_Rope(query, key, head_dim, seq_len,  num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-0.0113, -0.0217],\n",
       "           [ 0.0164, -0.0711],\n",
       "           [ 0.0026, -0.0137],\n",
       "           [-0.0110, -0.0263],\n",
       "           [ 0.0261, -0.0399],\n",
       "           [ 0.0448,  0.0577]],\n",
       " \n",
       "          [[-0.0369, -0.0231],\n",
       "           [ 0.0025, -0.0622],\n",
       "           [ 0.0677,  0.0699],\n",
       "           [ 0.0649, -0.0412],\n",
       "           [ 0.0105, -0.0802],\n",
       "           [-0.0488, -0.0284]],\n",
       " \n",
       "          [[ 0.0018,  0.0096],\n",
       "           [-0.0681, -0.0234],\n",
       "           [-0.0098, -0.0375],\n",
       "           [-0.0772, -0.0972],\n",
       "           [ 0.0373,  0.0051],\n",
       "           [ 0.0964, -0.0133]],\n",
       " \n",
       "          [[-0.0120,  0.0402],\n",
       "           [ 0.0536,  0.0630],\n",
       "           [ 0.0578,  0.0300],\n",
       "           [-0.0002, -0.0895],\n",
       "           [ 0.0079,  0.0557],\n",
       "           [-0.0040, -0.0034]]]]),\n",
       " tensor([[[[-0.0682,  0.0924],\n",
       "           [-0.0460, -0.0850],\n",
       "           [ 0.1103,  0.0256],\n",
       "           [-0.0496,  0.0828],\n",
       "           [ 0.0406, -0.0557],\n",
       "           [-0.1524, -0.1085]],\n",
       " \n",
       "          [[-0.0166,  0.0247],\n",
       "           [-0.0321, -0.0137],\n",
       "           [ 0.0137, -0.0427],\n",
       "           [ 0.0125,  0.0094],\n",
       "           [-0.0966, -0.0218],\n",
       "           [ 0.0438,  0.0521]]]]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_rotated, key_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0372, -0.0752],\n",
       "          [-0.0334, -0.1026],\n",
       "          [-0.0387,  0.0184],\n",
       "          [-0.0112, -0.0671],\n",
       "          [-0.0131,  0.0943],\n",
       "          [ 0.1154,  0.0390]],\n",
       "\n",
       "         [[-0.0424,  0.0104],\n",
       "          [ 0.0050, -0.0126],\n",
       "          [ 0.0497, -0.0733],\n",
       "          [-0.0189, -0.0172],\n",
       "          [-0.0999, -0.0100],\n",
       "          [ 0.0345, -0.0383]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x, n_rep):\n",
    "\n",
    "    bsz, num_key_value_heads, seq_len, head_dim = x.shape\n",
    "\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    \n",
    "    x = x[:, :, None, :, :].expand(bsz, num_key_value_heads, n_rep, seq_len, head_dim)\n",
    "    return x.reshape(bsz, num_key_value_heads * n_rep, seq_len, head_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_rotated = repeat_kv(key_rotated, n_rep)\n",
    "value = repeat_kv(value, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 6, 2]), torch.Size([1, 4, 6, 2]), torch.Size([1, 4, 6, 2]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key_rotated.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def self_attention_rope(query, key, value, attn_mask = None, scale = None, is_causal=False):\n",
    "\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "\n",
    "    if is_causal:\n",
    "        assert attn_mask is None\n",
    "        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "        attn_bias.to(query.dtype)\n",
    "\n",
    "    \n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.bool:\n",
    "            attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "        else:\n",
    "            attn_bias += attn_mask\n",
    "\n",
    "\n",
    "\n",
    "    # (bsz, num_heads, tgt_len, head_dim) @ (bsz, num_heads, head_dim, tgt_len) -> (bsz, num_heads, tgt_len, tgt_len) \n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "\n",
    "    # (bsz, num_heads, tgt_len, tgt_len) \n",
    "    attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "\n",
    "\n",
    "    sum_last_dim = attn_weight.sum(dim=-1)\n",
    "    tolerance = 1e-6  \n",
    "    assert torch.allclose(sum_last_dim, torch.ones_like(sum_last_dim), atol=tolerance), \"Attention weights sum is not approximately equal to 1\"\n",
    "\n",
    "\n",
    "    # # (bsz, num_heads, tgt_len, tgt_len) @ (bsz, num_heads, tgt_len, head_dim) -> (bsz, num_heads, tgt_len, head_dim) \n",
    "    attn_output = attn_weight @ value\n",
    "\n",
    "    print(\"ATTEN OUTPUT = \", attn_output)\n",
    "\n",
    "    return attn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False],\n",
       "        [ True,  True, False, False, False, False],\n",
       "        [ True,  True,  True, False, False, False],\n",
       "        [False,  True,  True,  True, False, False],\n",
       "        [False, False,  True,  True,  True, False],\n",
       "        [False, False, False,  True,  True,  True]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = src_tokenized.shape[1]\n",
    "sliding_window_len = 3\n",
    "\n",
    "sliding_window_mask =  (1 - torch.triu(torch.ones(seq_length, seq_length), diagonal=1)).bool()\n",
    "\n",
    "# print(sliding_window_mask)\n",
    "\n",
    "for i in range(sliding_window_mask.shape[0]-1, -1, -1):\n",
    "\n",
    "    li = i - sliding_window_len + 1\n",
    "\n",
    "    if li > 0:\n",
    "\n",
    "        sliding_window_mask[i][0:li] = False\n",
    "\n",
    "sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATTEN OUTPUT =  tensor([[[[-0.0372, -0.0752],\n",
      "          [-0.0353, -0.0889],\n",
      "          [-0.0364, -0.0531],\n",
      "          [-0.0278, -0.0505],\n",
      "          [-0.0210,  0.0153],\n",
      "          [ 0.0301,  0.0219]],\n",
      "\n",
      "         [[-0.0372, -0.0752],\n",
      "          [-0.0353, -0.0889],\n",
      "          [-0.0364, -0.0529],\n",
      "          [-0.0278, -0.0503],\n",
      "          [-0.0210,  0.0154],\n",
      "          [ 0.0306,  0.0221]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [-0.0187, -0.0011],\n",
      "          [ 0.0041, -0.0252],\n",
      "          [ 0.0120, -0.0344],\n",
      "          [-0.0230, -0.0335],\n",
      "          [-0.0279, -0.0219]],\n",
      "\n",
      "         [[-0.0424,  0.0104],\n",
      "          [-0.0187, -0.0011],\n",
      "          [ 0.0041, -0.0252],\n",
      "          [ 0.0120, -0.0344],\n",
      "          [-0.0230, -0.0335],\n",
      "          [-0.0281, -0.0218]]]])\n"
     ]
    }
   ],
   "source": [
    "self_attn_op = self_attention_rope(query_rotated, key_rotated, value, attn_mask = sliding_window_mask, is_causal=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 6, 2])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attn_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_proj_self_attn(self_attn_op, W, embed_dim):\n",
    "\n",
    "    self_attn_op = self_attn_op.transpose(1, 2).contiguous()\n",
    "    self_attn_op = self_attn_op.reshape(bsz, q_len, embed_dim)\n",
    "    return self_attn_op@W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "Wo = state_dict[\"layers.0.self_attn.o_proj.weight\"]\n",
    "print(Wo.shape)\n",
    "\n",
    "sa_output = out_proj_self_attn(self_attn_op, Wo, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-5.4631e-04, -4.2851e-04, -2.7580e-03,  3.4945e-04,  1.8132e-03,\n",
       "          -9.3882e-05, -1.9177e-03, -1.4553e-05],\n",
       "         [ 4.6210e-04, -6.6375e-04, -3.0637e-03,  4.6621e-04,  3.0429e-03,\n",
       "          -2.9930e-04,  3.0276e-04, -2.4526e-03],\n",
       "         [ 1.6153e-03, -2.3367e-04, -1.4735e-03,  5.7002e-04,  2.9275e-03,\n",
       "          -7.5637e-04,  2.8188e-03, -3.0160e-03],\n",
       "         [ 2.0543e-03, -1.8132e-04, -1.3591e-03, -6.8881e-05,  3.3867e-03,\n",
       "          -1.0794e-03,  3.4974e-03, -3.6740e-03],\n",
       "         [ 8.1219e-04,  8.0704e-04,  7.4197e-04, -1.1923e-03,  6.8060e-04,\n",
       "          -1.2882e-03,  3.6161e-04,  1.4475e-03],\n",
       "         [-1.1690e-04,  7.3303e-04,  4.5419e-04, -3.7673e-03,  3.0093e-04,\n",
       "          -1.3759e-03, -2.1586e-03,  2.1960e-03]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_output\n",
    "\n",
    "# check and verified "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0079, -0.0258,  0.0040,  0.0116,  0.0333,  0.0373,  0.0146,\n",
       "          -0.0181],\n",
       "         [-0.0126,  0.0211,  0.0195,  0.0529,  0.0132,  0.0360,  0.0036,\n",
       "          -0.0161],\n",
       "         [-0.0293,  0.0207, -0.0229,  0.0271, -0.0118, -0.0251,  0.0378,\n",
       "           0.0220],\n",
       "         [-0.0117, -0.0132,  0.0125,  0.0085, -0.0016, -0.0002, -0.0036,\n",
       "           0.0047],\n",
       "         [ 0.0384, -0.0118,  0.0074, -0.0021,  0.0192, -0.0385, -0.0125,\n",
       "           0.0218],\n",
       "         [-0.0162,  0.0156,  0.0074, -0.0136, -0.0115, -0.0137,  0.0155,\n",
       "           0.0388]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = residual + sa_output\n",
    "\n",
    "hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3540, -1.1556,  0.1783,  0.5175,  1.4878,  1.6687,  0.6509,\n",
       "          -0.8112],\n",
       "         [-0.4757,  0.7970,  0.7350,  1.9997,  0.4985,  1.3595,  0.1342,\n",
       "          -0.6091],\n",
       "         [-1.1389,  0.8025, -0.8887,  1.0517, -0.4577, -0.9731,  1.4679,\n",
       "           0.8553],\n",
       "         [-1.2954, -1.4519,  1.3833,  0.9339, -0.1723, -0.0233, -0.3952,\n",
       "           0.5166],\n",
       "         [ 1.6706, -0.5140,  0.3236, -0.0921,  0.8347, -1.6713, -0.5417,\n",
       "           0.9473],\n",
       "         [-0.8497,  0.8217,  0.3899, -0.7164, -0.6033, -0.7204,  0.8158,\n",
       "           2.0416]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = apply_layernorm(hidden_states, state_dict[\"layers.0.post_attention_layernorm.weight\"], variance_epsilon = 1e-05)\n",
    "\n",
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only when 'pretraining_tp == 1'\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def llama_mlp(x, W_down_proj,W_up_proj, W_gate_proj):\n",
    "    \n",
    "    up_proj =  x@W_up_proj.T\n",
    "    gate_proj =  x@W_gate_proj.T\n",
    "\n",
    "    print(\"UP PROJ = \", up_proj)\n",
    "    print()\n",
    "\n",
    "    print(\"GATE PROJ = \", gate_proj)\n",
    "    print()\n",
    "\n",
    "    temp_proj = up_proj * gate_proj\n",
    "\n",
    "    silu = nn.SiLU()\n",
    "\n",
    "    temp_proj = silu(temp_proj)\n",
    "\n",
    "    print(\"ACT = \",temp_proj)\n",
    "\n",
    "    down_proj = temp_proj@W_down_proj.T\n",
    "\n",
    "    return down_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_down_proj = state_dict[\"layers.0.mlp.down_proj.weight\"]\n",
    "\n",
    "W_up_proj = state_dict[\"layers.0.mlp.up_proj.weight\"]\n",
    "\n",
    "W_gate_proj = state_dict[\"layers.0.mlp.gate_proj.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP PROJ =  tensor([[[-0.0263, -0.0374,  0.0362,  0.0202,  0.0470,  0.0156, -0.0283,\n",
      "           0.0319],\n",
      "         [-0.1024,  0.0197, -0.0321, -0.0052,  0.0641,  0.0524, -0.0015,\n",
      "           0.0010],\n",
      "         [-0.0693, -0.0265, -0.0288,  0.0949,  0.0505,  0.0963, -0.0361,\n",
      "           0.0130],\n",
      "         [-0.0328,  0.0717, -0.0256, -0.0183,  0.0024,  0.0042, -0.0562,\n",
      "          -0.0220],\n",
      "         [ 0.0753,  0.0299,  0.0040, -0.0840, -0.0625, -0.0627, -0.1109,\n",
      "          -0.0362],\n",
      "         [-0.0098,  0.0205, -0.0038, -0.0214,  0.0036,  0.0421, -0.0381,\n",
      "          -0.0661]]])\n",
      "\n",
      "GATE PROJ =  tensor([[[-3.3223e-02,  1.1813e-01, -3.4386e-02, -1.7299e-02, -2.8870e-02,\n",
      "          -3.1325e-02, -9.3374e-03, -3.7493e-02],\n",
      "         [-3.8423e-02,  7.7386e-02, -7.7597e-02, -1.1311e-01, -3.3710e-03,\n",
      "          -5.1375e-02,  1.0571e-04, -1.0072e-01],\n",
      "         [ 7.4562e-02, -1.8549e-02,  7.8605e-03,  4.1163e-02, -1.6428e-02,\n",
      "          -3.1222e-02, -3.1268e-02,  1.4060e-02],\n",
      "         [ 9.3609e-03, -3.4470e-02, -3.7460e-02, -2.4655e-02,  5.7552e-02,\n",
      "           7.7997e-03, -4.3633e-02, -7.7975e-02],\n",
      "         [ 6.7290e-02,  5.0164e-02, -1.7442e-02, -3.3551e-03,  4.0004e-02,\n",
      "           4.5992e-02, -1.8123e-02,  4.7793e-03],\n",
      "         [ 1.3719e-01, -9.3006e-02,  2.9840e-02,  1.3074e-01, -6.3342e-02,\n",
      "           6.8296e-03, -3.0387e-02, -1.6806e-02]]])\n",
      "\n",
      "ACT =  tensor([[[ 4.3763e-04, -2.2031e-03, -6.2170e-04, -1.7461e-04, -6.7735e-04,\n",
      "          -2.4433e-04,  1.3199e-04, -5.9700e-04],\n",
      "         [ 1.9712e-03,  7.6277e-04,  1.2484e-03,  2.9186e-04, -1.0807e-04,\n",
      "          -1.3449e-03, -7.9977e-08, -4.9561e-05],\n",
      "         [-2.5767e-03,  2.4577e-04, -1.1337e-04,  1.9574e-03, -4.1484e-04,\n",
      "          -1.5015e-03,  5.6445e-04,  9.1304e-05],\n",
      "         [-1.5343e-04, -1.2334e-03,  4.7992e-04,  2.2530e-04,  6.8453e-05,\n",
      "           1.6190e-05,  1.2276e-03,  8.5882e-04],\n",
      "         [ 2.5414e-03,  7.4980e-04, -3.4477e-05,  1.4086e-04, -1.2478e-03,\n",
      "          -1.4386e-03,  1.0058e-03, -8.6613e-05],\n",
      "         [-6.6887e-04, -9.5059e-04, -5.6018e-05, -1.3963e-03, -1.1540e-04,\n",
      "           1.4383e-04,  5.7994e-04,  5.5605e-04]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1604e-04,  1.0476e-04,  5.0113e-05,  8.0561e-06,  3.7039e-05,\n",
       "           6.7447e-05,  4.9149e-07, -2.5759e-06],\n",
       "         [ 4.9020e-06,  1.3651e-05,  2.6720e-05, -9.1400e-05,  2.5665e-05,\n",
       "          -4.4363e-05,  9.8443e-06, -1.4415e-05],\n",
       "         [-5.1641e-05, -1.4457e-05, -7.2304e-05,  1.1696e-05, -6.9724e-05,\n",
       "           5.1070e-05, -5.3767e-05, -4.8957e-05],\n",
       "         [-1.6031e-05,  1.7560e-05,  9.4520e-06, -4.8031e-05, -1.9137e-05,\n",
       "          -2.3326e-05, -2.9325e-05, -2.1525e-05],\n",
       "         [ 1.5106e-05,  1.4085e-05,  1.0385e-04, -2.3431e-05, -7.3604e-06,\n",
       "           6.7487e-05,  7.6150e-05, -1.7018e-06],\n",
       "         [-1.2456e-05,  2.0832e-05,  8.2834e-06, -4.5761e-06, -2.8004e-05,\n",
       "          -5.5918e-05,  2.3039e-05, -1.7661e-05]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = llama_mlp(hidden_state, W_down_proj,W_up_proj, W_gate_proj)\n",
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state = hidden_state + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0080, -0.0257,  0.0040,  0.0116,  0.0333,  0.0374,  0.0146,\n",
       "          -0.0181],\n",
       "         [-0.0126,  0.0211,  0.0195,  0.0529,  0.0132,  0.0360,  0.0036,\n",
       "          -0.0161],\n",
       "         [-0.0294,  0.0207, -0.0230,  0.0271, -0.0119, -0.0250,  0.0377,\n",
       "           0.0220],\n",
       "         [-0.0118, -0.0131,  0.0125,  0.0084, -0.0016, -0.0002, -0.0036,\n",
       "           0.0047],\n",
       "         [ 0.0385, -0.0118,  0.0076, -0.0021,  0.0192, -0.0384, -0.0124,\n",
       "           0.0218],\n",
       "         [-0.0162,  0.0156,  0.0074, -0.0136, -0.0115, -0.0138,  0.0155,\n",
       "           0.0388]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
