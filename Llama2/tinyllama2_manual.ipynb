{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "SEED = 6\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LlamaConfig {\n",
       "  \"architectures\": [\n",
       "    \"LlamaForCausalLM\"\n",
       "  ],\n",
       "  \"attention_bias\": false,\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 8,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 5632,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"llama\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_hidden_layers\": 1,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-05,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.38.0.dev0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32000\n",
       "}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, LlamaConfig\n",
    "\n",
    "\n",
    "# Llama_config = LlamaConfig.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", num_hidden_layers = 1, use_cache = False, hidden_size = 4, num_attention_heads = 1, \n",
    "#                                            output_hidden_states=True,  num_key_value_heads = 1, past_key_values = True)\n",
    "\n",
    "\n",
    "Llama_config = LlamaConfig.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\", num_hidden_layers = 1, use_cache = False, hidden_size = 8, num_attention_heads = 4, \n",
    "                                           output_hidden_states=True,  num_key_value_heads = 2, past_key_values = True)\n",
    "\n",
    "\n",
    "Llama_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "tinyllama = AutoModel.from_config(Llama_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LlamaTokenizer\n",
    "\n",
    "src_sent = \"hi how are\"\n",
    "\n",
    "llama_tokenizer = LlamaTokenizer.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v1.0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[   1, 7251,  920,  526]]), 'attention_mask': tensor([[1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict = llama_tokenizer.encode_plus(src_sent, return_tensors='pt')\n",
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   1, 7251,  920,  526]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized = tokenized_src_dict[\"input_ids\"]\n",
    "src_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hi how are'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama_tokenizer.decode(*src_tokenized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying the RoPE of Llama2 \n",
    "\n",
    "### **GROUPED-QUERY ATTENTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_rep =  2\n"
     ]
    }
   ],
   "source": [
    "# head_dim = 4\n",
    "# num_heads = 1\n",
    "# seq_len = 4\n",
    "\n",
    "embed_dim = 8\n",
    "\n",
    "num_heads = 4\n",
    "\n",
    "n_heads_q = num_heads\n",
    "\n",
    "n_kv_heads = 2\n",
    "\n",
    "seq_len = 4\n",
    "\n",
    "head_dim = embed_dim // num_heads\n",
    "\n",
    "n_rep = n_heads_q//n_kv_heads\n",
    "print(\"n_rep = \", n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = tinyllama.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def look_up_table(sentence, vocab_embeds, embedding):\n",
    "\n",
    "    for i in range(sentence.size(0)):\n",
    "        for j in range(sentence.size(1)):\n",
    "            \n",
    "            # Get the index for the current word token index in the sequence\n",
    "            word_index = sentence[i, j].item()\n",
    "\n",
    "            if word_index < 0 or word_index >= vocab_embeds.size(0):\n",
    "                raise ValueError(f\"Invalid word index: {word_index}\")\n",
    "\n",
    "            # Lookup the corresponding embedding vector for the word\n",
    "            embedding[i, j, :] = vocab_embeds[word_index, :]\n",
    "\n",
    "            print(f\"Word index: {word_index}, Embedding: {vocab_embeds[word_index, :]}\")\n",
    "    print()\n",
    "\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source sentence embedding\n",
      "Word index: 1, Embedding: tensor([-0.0258,  0.0210, -0.0483, -0.0079, -0.0164, -0.0140, -0.0164, -0.0006])\n",
      "Word index: 7251, Embedding: tensor([ 0.0074, -0.0400,  0.0304, -0.0152,  0.0153,  0.0289,  0.0037,  0.0250])\n",
      "Word index: 920, Embedding: tensor([ 0.0291,  0.0036, -0.0103, -0.0144,  0.0057, -0.0030, -0.0159, -0.0409])\n",
      "Word index: 526, Embedding: tensor([ 0.0214, -0.0114, -0.0003,  0.0414,  0.0012,  0.0080, -0.0227,  0.0104])\n",
      "\n",
      "torch.Size([1, 4, 8])\n",
      "Source embeddings : \n",
      "\n",
      "tensor([[[-0.0258,  0.0210, -0.0483, -0.0079, -0.0164, -0.0140, -0.0164,\n",
      "          -0.0006],\n",
      "         [ 0.0074, -0.0400,  0.0304, -0.0152,  0.0153,  0.0289,  0.0037,\n",
      "           0.0250],\n",
      "         [ 0.0291,  0.0036, -0.0103, -0.0144,  0.0057, -0.0030, -0.0159,\n",
      "          -0.0409],\n",
      "         [ 0.0214, -0.0114, -0.0003,  0.0414,  0.0012,  0.0080, -0.0227,\n",
      "           0.0104]]])\n"
     ]
    }
   ],
   "source": [
    "def get_embedding_outputs(src_tokens, state_dict, d_model):\n",
    "\n",
    "    src_vocab_embeds = state_dict[\"embed_tokens.weight\"]\n",
    "\n",
    "    src_embedding = torch.zeros(src_tokens.size(0), src_tokens.size(1), d_model)\n",
    "    print(\"Source sentence embedding\")\n",
    "    src_embedding =  look_up_table(src_tokens, src_vocab_embeds, src_embedding)\n",
    "    print(src_embedding.shape)\n",
    "\n",
    "\n",
    "    print(\"Source embeddings : \\n\")\n",
    "    print(src_embedding)\n",
    "\n",
    "    return src_embedding\n",
    "\n",
    "\n",
    "input_embeddings = get_embedding_outputs(src_tokenized, state_dict, d_model = embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = input_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_layernorm(hidden_states, wt, variance_epsilon = 1e-05):\n",
    "\n",
    "    dtype =  hidden_states.dtype\n",
    "    hidden_states = hidden_states.to(torch.float32)\n",
    "    variance = hidden_states.pow(2).mean(-1, keepdim=True)\n",
    "    hidden_states = hidden_states * torch.rsqrt(variance + variance_epsilon)\n",
    "    op = wt * hidden_states\n",
    "    return op.to(dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.1118,  0.9048, -2.0794, -0.3405, -0.7058, -0.6022, -0.7040,\n",
       "          -0.0255],\n",
       "         [ 0.3099, -1.6691,  1.2685, -0.6328,  0.6387,  1.2049,  0.1544,\n",
       "           1.0419],\n",
       "         [ 1.4492,  0.1812, -0.5150, -0.7174,  0.2862, -0.1514, -0.7926,\n",
       "          -2.0385],\n",
       "         [ 1.0946, -0.5810, -0.0146,  2.1127,  0.0634,  0.4081, -1.1568,\n",
       "           0.5321]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = apply_layernorm(input_embeddings, state_dict[\"layers.0.input_layernorm.weight\"], variance_epsilon = 1e-05)\n",
    "\n",
    "hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['embed_tokens.weight', 'layers.0.self_attn.q_proj.weight', 'layers.0.self_attn.k_proj.weight', 'layers.0.self_attn.v_proj.weight', 'layers.0.self_attn.o_proj.weight', 'layers.0.mlp.gate_proj.weight', 'layers.0.mlp.up_proj.weight', 'layers.0.mlp.down_proj.weight', 'layers.0.input_layernorm.weight', 'layers.0.post_attention_layernorm.weight', 'norm.weight'])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_qkv(hidden_state ,Wq, Wk, Wv):\n",
    "\n",
    "\n",
    "    q_matmul = hidden_state@Wq.T\n",
    "    k_matmul = hidden_state@Wk.T\n",
    "    v_matmul = hidden_state@Wv.T\n",
    "\n",
    "    return q_matmul, k_matmul, v_matmul\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wq = state_dict[\"layers.0.self_attn.q_proj.weight\"]\n",
    "Wk = state_dict[\"layers.0.self_attn.k_proj.weight\"]\n",
    "Wv = state_dict[\"layers.0.self_attn.v_proj.weight\"]\n",
    "query, key, value = get_qkv(hidden_state ,Wq, Wk, Wv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.0507,  0.0144,  0.0718, -0.0079, -0.0578,  0.0141, -0.1129,\n",
       "            0.0667],\n",
       "          [-0.0108,  0.0590, -0.0587,  0.0913,  0.0326, -0.0691,  0.0018,\n",
       "           -0.0266],\n",
       "          [-0.0745,  0.0044,  0.0250, -0.1372,  0.0829,  0.0847,  0.0965,\n",
       "           -0.1339],\n",
       "          [-0.0155, -0.0212, -0.0371,  0.0443, -0.0387, -0.0826,  0.0557,\n",
       "            0.0384]]]),\n",
       " tensor([[[-0.0798, -0.0299, -0.0730, -0.0716],\n",
       "          [ 0.0677,  0.0232,  0.0885,  0.0634],\n",
       "          [-0.0026, -0.0251, -0.0366,  0.0742],\n",
       "          [-0.0431, -0.0219,  0.0021, -0.0356]]]),\n",
       " tensor([[[ 0.0016, -0.0609, -0.0340, -0.0412],\n",
       "          [ 0.0243,  0.0421, -0.0112, -0.0031],\n",
       "          [-0.0515,  0.0227, -0.0062,  0.0636],\n",
       "          [ 0.0180,  0.0050,  0.0095, -0.0304]]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query, key, value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sin_cos(dim, seq_len, max_seq_len, base = 10000):\n",
    "\n",
    "    inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float() / dim))\n",
    "\n",
    "    t = torch.arange(max_seq_len, dtype=torch.int64).type_as(inv_freq)\n",
    "\n",
    "    freqs = torch.outer(t, inv_freq)\n",
    "    \n",
    "    # Uses a different permutation in order to obtain the same calculation\n",
    "    emb = torch.cat((freqs, freqs), dim=-1) \n",
    "\n",
    "    return  emb.cos()[:seq_len], emb.sin()[:seq_len]\n",
    "\n",
    "\n",
    "def rotate_half(x):\n",
    "\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "\n",
    "    # print(x1.shape, x2.shape)\n",
    "    # x1 = x[ : , : x.shape[-1] // 2]\n",
    "    # x2 = x[ : , x.shape[-1] // 2 :]\n",
    "\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=1):\n",
    "\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    # print(\"HALF ROT SHAPES = \")\n",
    "    # print((rotate_half(q).shape,   sin.shape))\n",
    "    # print((rotate_half(k).shape , sin.shape))\n",
    "\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "    return q_embed, k_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 8]), torch.Size([1, 4, 4]), torch.Size([1, 4, 4]))"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bsz, q_len, _ = query.shape\n",
    "\n",
    "query = query.view(bsz, q_len, n_heads_q, head_dim).transpose(1, 2)\n",
    "key = key.view(bsz, q_len, n_kv_heads, head_dim).transpose(1, 2)\n",
    "value = value.view(bsz, q_len, n_kv_heads, head_dim).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 4, 2]), torch.Size([1, 2, 4, 2]), torch.Size([1, 2, 4, 2]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_half(x):\n",
    "\n",
    "    x1 = x[..., : x.shape[-1] // 2]\n",
    "    x2 = x[..., x.shape[-1] // 2 :]\n",
    "\n",
    "    # print(x1.shape, x2.shape)\n",
    "    # x1 = x[ : , : x.shape[-1] // 2]\n",
    "    # x2 = x[ : , x.shape[-1] // 2 :]\n",
    "\n",
    "    return torch.cat((-x2, x1), dim=-1)\n",
    "\n",
    "def apply_rotary_pos_emb(q, k, cos, sin, unsqueeze_dim=1):\n",
    "\n",
    "    cos = cos.unsqueeze(unsqueeze_dim)\n",
    "    sin = sin.unsqueeze(unsqueeze_dim)\n",
    "\n",
    "    print(cos.shape, sin.shape)\n",
    "    print(q.shape, k.shape)\n",
    "\n",
    "    # print(\"HALF ROT SHAPES = \")\n",
    "    # print((rotate_half(q).shape,   sin.shape))\n",
    "    # print((rotate_half(k).shape , sin.shape))\n",
    "    q_embed = (q * cos) + (rotate_half(q) * sin)\n",
    "    k_embed = (k * cos) + (rotate_half(k) * sin)\n",
    "\n",
    "    return q_embed, k_embed\n",
    "\n",
    "def get_Rope(query, key, head_dim, seq_len,  num_heads):\n",
    "\n",
    "    cos, sin = get_sin_cos(dim = head_dim, seq_len = seq_len, max_seq_len = 2048, base = 10000)\n",
    "\n",
    "    cos = cos.unsqueeze(0)\n",
    "    sin = sin.unsqueeze(0)\n",
    "\n",
    "    print(cos.shape, sin.shape)\n",
    "\n",
    "    q_rotated, k_rotated = apply_rotary_pos_emb(query, key, cos, sin, unsqueeze_dim=1)\n",
    "\n",
    "    return q_rotated, k_rotated\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4, 2]) torch.Size([1, 4, 2])\n",
      "torch.Size([1, 1, 4, 2]) torch.Size([1, 1, 4, 2])\n",
      "torch.Size([1, 4, 4, 2]) torch.Size([1, 2, 4, 2])\n"
     ]
    }
   ],
   "source": [
    "query_rotated, key_rotated = get_Rope(query, key, head_dim, seq_len,  num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 5.0677e-02,  1.4430e-02],\n",
       "           [-5.5456e-02,  2.2768e-02],\n",
       "           [ 2.7001e-02, -6.9541e-02],\n",
       "           [ 1.8380e-02,  1.8795e-02]],\n",
       " \n",
       "          [[ 7.1790e-02, -7.9177e-03],\n",
       "           [-1.0855e-01, -2.3097e-06],\n",
       "           [ 1.1433e-01,  7.9771e-02],\n",
       "           [ 3.0465e-02, -4.9116e-02]],\n",
       " \n",
       "          [[-5.7788e-02,  1.4150e-02],\n",
       "           [ 7.5767e-02, -9.9350e-03],\n",
       "           [-1.1151e-01,  4.0088e-02],\n",
       "           [ 5.0002e-02,  7.6326e-02]],\n",
       " \n",
       "          [[-1.1291e-01,  6.6661e-02],\n",
       "           [ 2.3330e-02, -1.2850e-02],\n",
       "           [ 8.1624e-02,  1.4343e-01],\n",
       "           [-6.0592e-02, -3.0113e-02]]]]),\n",
       " tensor([[[[-0.0798, -0.0299],\n",
       "           [ 0.0171,  0.0695],\n",
       "           [ 0.0239,  0.0081],\n",
       "           [ 0.0458,  0.0156]],\n",
       " \n",
       "          [[-0.0730, -0.0716],\n",
       "           [-0.0055,  0.1087],\n",
       "           [-0.0523, -0.0641],\n",
       "           [ 0.0030,  0.0355]]]]))"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_rotated, key_rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0016, -0.0609],\n",
       "          [ 0.0243,  0.0421],\n",
       "          [-0.0515,  0.0227],\n",
       "          [ 0.0180,  0.0050]],\n",
       "\n",
       "         [[-0.0340, -0.0412],\n",
       "          [-0.0112, -0.0031],\n",
       "          [-0.0062,  0.0636],\n",
       "          [ 0.0095, -0.0304]]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_kv(x, n_rep):\n",
    "\n",
    "    bsz, num_key_value_heads, seq_len, head_dim = x.shape\n",
    "\n",
    "    if n_rep == 1:\n",
    "        return x\n",
    "    \n",
    "    x = x[:, :, None, :, :].expand(bsz, num_key_value_heads, n_rep, seq_len, head_dim)\n",
    "    return x.reshape(bsz, num_key_value_heads * n_rep, seq_len, head_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_rotated = repeat_kv(key_rotated, n_rep)\n",
    "value = repeat_kv(value, n_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 4, 4, 2]), torch.Size([1, 4, 4, 2]), torch.Size([1, 4, 4, 2]))"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.shape, key_rotated.shape, value.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def self_attention_rope(query, key, value, attn_mask = None, scale = None, is_causal=False):\n",
    "\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    attn_bias = torch.zeros(L, S, dtype=query.dtype)\n",
    "\n",
    "    if is_causal:\n",
    "        assert attn_mask is None\n",
    "        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal=0)\n",
    "        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "        attn_bias.to(query.dtype)\n",
    "\n",
    "    \n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.bool:\n",
    "            attn_bias.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "        else:\n",
    "            attn_bias += attn_mask\n",
    "\n",
    "\n",
    "\n",
    "    # (bsz, num_heads, tgt_len, head_dim) @ (bsz, num_heads, head_dim, tgt_len) -> (bsz, num_heads, tgt_len, tgt_len) \n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "\n",
    "    # (bsz, num_heads, tgt_len, tgt_len) \n",
    "    attn_weight = torch.softmax(attn_weight, dim=-1)\n",
    "\n",
    "    print(\"attn weight = \", attn_weight)\n",
    "\n",
    "\n",
    "    sum_last_dim = attn_weight.sum(dim=-1)\n",
    "    tolerance = 1e-6  \n",
    "    assert torch.allclose(sum_last_dim, torch.ones_like(sum_last_dim), atol=tolerance), \"Attention weights sum is not approximately equal to 1\"\n",
    "\n",
    "\n",
    "    # # (bsz, num_heads, tgt_len, tgt_len) @ (bsz, num_heads, tgt_len, head_dim) -> (bsz, num_heads, tgt_len, head_dim) \n",
    "    attn_output = attn_weight @ value\n",
    "\n",
    "    print(\"ATTEN OUTPUT = \", attn_output)\n",
    "\n",
    "    return attn_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn weight =  tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5005, 0.4995, 0.0000, 0.0000],\n",
      "          [0.3337, 0.3326, 0.3337, 0.0000],\n",
      "          [0.2496, 0.2502, 0.2500, 0.2501]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5019, 0.4981, 0.0000, 0.0000],\n",
      "          [0.3307, 0.3351, 0.3342, 0.0000],\n",
      "          [0.2500, 0.2496, 0.2502, 0.2502]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4994, 0.5006, 0.0000, 0.0000],\n",
      "          [0.3335, 0.3334, 0.3330, 0.0000],\n",
      "          [0.2486, 0.2517, 0.2489, 0.2508]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5001, 0.4999, 0.0000, 0.0000],\n",
      "          [0.3306, 0.3381, 0.3313, 0.0000],\n",
      "          [0.2508, 0.2491, 0.2506, 0.2494]]]])\n",
      "ATTEN OUTPUT =  tensor([[[[ 0.0016, -0.0609],\n",
      "          [ 0.0129, -0.0094],\n",
      "          [-0.0086,  0.0013],\n",
      "          [-0.0019,  0.0023]],\n",
      "\n",
      "         [[ 0.0016, -0.0609],\n",
      "          [ 0.0129, -0.0096],\n",
      "          [-0.0085,  0.0016],\n",
      "          [-0.0019,  0.0022]],\n",
      "\n",
      "         [[-0.0340, -0.0412],\n",
      "          [-0.0226, -0.0221],\n",
      "          [-0.0172,  0.0064],\n",
      "          [-0.0104, -0.0028]],\n",
      "\n",
      "         [[-0.0340, -0.0412],\n",
      "          [-0.0226, -0.0221],\n",
      "          [-0.0171,  0.0064],\n",
      "          [-0.0105, -0.0027]]]])\n"
     ]
    }
   ],
   "source": [
    "self_attn_op = self_attention_rope(query_rotated, key_rotated, value, attn_mask = None, is_causal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 4, 2])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_attn_op.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_proj_self_attn(self_attn_op, W, embed_dim):\n",
    "\n",
    "    self_attn_op = self_attn_op.transpose(1, 2).contiguous()\n",
    "    self_attn_op = self_attn_op.reshape(bsz, q_len, embed_dim)\n",
    "    return self_attn_op@W.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    }
   ],
   "source": [
    "Wo = state_dict[\"layers.0.self_attn.o_proj.weight\"]\n",
    "print(Wo.shape)\n",
    "\n",
    "sa_output = out_proj_self_attn(self_attn_op, Wo, embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 7.2769e-03, -2.6772e-03,  5.2673e-03, -8.7639e-05,  5.1127e-05,\n",
       "           2.1528e-03, -5.8406e-03, -1.3345e-03],\n",
       "         [ 3.0233e-03, -1.5681e-03,  2.1389e-03,  1.0173e-03,  4.9285e-04,\n",
       "           6.7958e-05, -3.4745e-03, -3.2432e-04],\n",
       "         [-1.2038e-03,  3.6274e-04,  3.0120e-04, -1.1266e-04, -1.5346e-04,\n",
       "           3.7689e-04, -2.5342e-04, -1.3245e-03],\n",
       "         [ 2.0138e-05, -1.6477e-04,  4.0039e-04,  1.5589e-04,  6.1682e-05,\n",
       "           3.0537e-05, -6.1216e-04, -4.5421e-04]]])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sa_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0186,  0.0183, -0.0430, -0.0080, -0.0163, -0.0118, -0.0222,\n",
       "          -0.0019],\n",
       "         [ 0.0104, -0.0415,  0.0325, -0.0141,  0.0158,  0.0289,  0.0002,\n",
       "           0.0246],\n",
       "         [ 0.0279,  0.0040, -0.0100, -0.0145,  0.0056, -0.0027, -0.0162,\n",
       "          -0.0422],\n",
       "         [ 0.0215, -0.0115,  0.0001,  0.0415,  0.0013,  0.0080, -0.0233,\n",
       "           0.0100]]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_states = residual + sa_output\n",
    "\n",
    "hidden_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "residual = hidden_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.8769,  0.8670, -2.0344, -0.3781, -0.7726, -0.5595, -1.0491,\n",
       "          -0.0911],\n",
       "         [ 0.4236, -1.6847,  1.3187, -0.5734,  0.6403,  1.1730,  0.0090,\n",
       "           0.9987],\n",
       "         [ 1.3795,  0.1979, -0.4964, -0.7179,  0.2766, -0.1317, -0.7995,\n",
       "          -2.0897],\n",
       "         [ 1.0891, -0.5859,  0.0058,  2.1080,  0.0661,  0.4072, -1.1810,\n",
       "           0.5059]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = apply_layernorm(hidden_states, state_dict[\"layers.0.post_attention_layernorm.weight\"], variance_epsilon = 1e-05)\n",
    "\n",
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only when 'pretraining_tp == 1'\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "def llama_mlp(x, W_down_proj,W_up_proj, W_gate_proj):\n",
    "    \n",
    "    up_proj =  x@W_up_proj.T\n",
    "    gate_proj =  x@W_gate_proj.T\n",
    "\n",
    "    print(\"UP PROJ = \", up_proj)\n",
    "    print()\n",
    "\n",
    "    print(\"GATE PROJ = \", gate_proj)\n",
    "    print()\n",
    "\n",
    "    temp_proj = up_proj * gate_proj\n",
    "\n",
    "    silu = nn.SiLU()\n",
    "\n",
    "    temp_proj = silu(temp_proj)\n",
    "\n",
    "    print(\"ACT = \",temp_proj)\n",
    "\n",
    "    down_proj = temp_proj@W_down_proj.T\n",
    "\n",
    "    return down_proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_down_proj = state_dict[\"layers.0.mlp.down_proj.weight\"]\n",
    "\n",
    "W_up_proj = state_dict[\"layers.0.mlp.up_proj.weight\"]\n",
    "\n",
    "W_gate_proj = state_dict[\"layers.0.mlp.gate_proj.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UP PROJ =  tensor([[[-0.0796, -0.0497, -0.1191,  ..., -0.0259,  0.0210, -0.0127],\n",
      "         [ 0.0585,  0.0547,  0.0888,  ...,  0.0021, -0.0128,  0.0241],\n",
      "         [-0.0024, -0.0741, -0.0656,  ..., -0.1007, -0.0907, -0.0512],\n",
      "         [ 0.0014,  0.0548,  0.0600,  ..., -0.0253, -0.0084,  0.0511]]])\n",
      "\n",
      "GATE PROJ =  tensor([[[ 0.0527,  0.0807,  0.1029,  ..., -0.0380, -0.0192,  0.0034],\n",
      "         [-0.0608, -0.0465, -0.0959,  ..., -0.0405, -0.0408,  0.0139],\n",
      "         [ 0.0068,  0.0973, -0.0276,  ...,  0.0418,  0.0148,  0.0371],\n",
      "         [-0.0763, -0.0806, -0.0333,  ...,  0.0304,  0.0270,  0.0448]]])\n",
      "\n",
      "ACT =  tensor([[[-2.0931e-03, -2.0009e-03, -6.0904e-03,  ...,  4.9118e-04,\n",
      "          -2.0208e-04, -2.1336e-05],\n",
      "         [-1.7750e-03, -1.2702e-03, -4.2398e-03,  ..., -4.3319e-05,\n",
      "           2.6042e-04,  1.6809e-04],\n",
      "         [-8.1050e-06, -3.5940e-03,  9.0573e-04,  ..., -2.1021e-03,\n",
      "          -6.6901e-04, -9.4906e-04],\n",
      "         [-5.2391e-05, -2.2012e-03, -9.9823e-04,  ..., -3.8413e-04,\n",
      "          -1.1368e-04,  1.1448e-03]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-8.4654e-04, -9.3272e-04, -7.8715e-04,  1.3893e-03, -3.4011e-04,\n",
       "           1.0799e-03,  4.2394e-03,  1.2253e-03],\n",
       "         [ 2.5295e-03, -1.2564e-03, -3.1189e-03, -1.5183e-03, -1.7109e-04,\n",
       "           3.5854e-03,  2.0371e-03,  4.6839e-05],\n",
       "         [-5.8827e-04, -4.1202e-04, -4.8891e-03,  1.3620e-03, -1.8044e-03,\n",
       "           4.2751e-03,  1.1714e-03, -5.6578e-04],\n",
       "         [-3.1874e-04,  8.3021e-04,  1.9767e-03,  1.2665e-03,  1.4345e-03,\n",
       "          -1.0643e-03,  8.1463e-04, -1.9026e-03]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state = llama_mlp(hidden_state, W_down_proj,W_up_proj, W_gate_proj)\n",
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state = hidden_state + residual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0194,  0.0174, -0.0438, -0.0066, -0.0167, -0.0108, -0.0180,\n",
       "          -0.0007],\n",
       "         [ 0.0130, -0.0428,  0.0294, -0.0157,  0.0156,  0.0325,  0.0023,\n",
       "           0.0247],\n",
       "         [ 0.0273,  0.0036, -0.0149, -0.0131,  0.0038,  0.0016, -0.0150,\n",
       "          -0.0428],\n",
       "         [ 0.0211, -0.0107,  0.0021,  0.0428,  0.0027,  0.0070, -0.0225,\n",
       "           0.0081]]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
