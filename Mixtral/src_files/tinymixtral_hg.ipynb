{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.trainer_utils import set_seed\n",
    "import torch\n",
    "\n",
    "SEED = 6\n",
    "set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtralConfig {\n",
       "  \"_name_or_path\": \"NickyNicky/LocutusqueXFelladrin-TinyMistral248M-Instruct_oasst2_chatML_V4\",\n",
       "  \"architectures\": [\n",
       "    \"MixtralForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"silu\",\n",
       "  \"hidden_size\": 8,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8,\n",
       "  \"max_position_embeddings\": 32768,\n",
       "  \"model_type\": \"mixtral\",\n",
       "  \"num_attention_heads\": 4,\n",
       "  \"num_experts_per_tok\": 2,\n",
       "  \"num_hidden_layers\": 1,\n",
       "  \"num_key_value_heads\": 2,\n",
       "  \"num_local_experts\": 4,\n",
       "  \"output_hidden_states\": true,\n",
       "  \"output_router_logits\": false,\n",
       "  \"pretraining_tp\": 1,\n",
       "  \"rms_norm_eps\": 1e-06,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"router_aux_loss_coef\": 0.001,\n",
       "  \"sliding_window\": 3,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"torch_dtype\": \"bfloat16\",\n",
       "  \"transformers_version\": \"4.38.0.dev0\",\n",
       "  \"use_cache\": false,\n",
       "  \"vocab_size\": 32005\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoConfig, MixtralConfig\n",
    "\n",
    "\n",
    "mixtral_config = MixtralConfig.from_pretrained(\"NickyNicky/Mixtral-TinyMistral-8x248M-Instruct_oasst2_chatML_Intel_orca_dpo_pairs_DPO_V1\", num_hidden_layers = 1, use_cache = False, hidden_size = 8, num_attention_heads = 4, \n",
    "                                           output_hidden_states=True,  num_key_value_heads = 2, past_key_values = True, intermediate_size = 8, sliding_window = 3, dropout_p = 0, \n",
    "                                           \n",
    "                                           num_local_experts = 4, num_experts_per_tok = 2)\n",
    "\n",
    "\n",
    "mixtral_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "tinymixtral = AutoModel.from_config(mixtral_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "src_sent = \"hi how are you doing\"\n",
    "\n",
    "mistal_tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict = mistal_tokenizer.encode_plus(src_sent, return_tensors='pt')\n",
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_src_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1, 12014,   910,   460,   368,  2548]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized = tokenized_src_dict[\"input_ids\"]\n",
    "src_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> hi how are you doing'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistal_tokenizer.decode(*src_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[1, 1, 1, 1, 1, 1]]),\n",
      " 'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]])}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint \n",
    "\n",
    "pprint(tokenized_src_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch._VariableFunctionsClass.ones>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0.],\n",
       "        [0., 1., 1., 1., 0., 0.],\n",
       "        [0., 0., 1., 1., 1., 0.],\n",
       "        [0., 0., 0., 1., 1., 1.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_length = src_tokenized.shape[1]\n",
    "sliding_window_len = 3\n",
    "\n",
    "sliding_window_mask = 1 - (torch.triu(torch.ones(seq_length, seq_length), diagonal=1))\n",
    "\n",
    "\n",
    "for i in range(sliding_window_mask.shape[0]-1, -1, -1):\n",
    "\n",
    "    li = i - sliding_window_len + 1\n",
    "\n",
    "\n",
    "    if li > 0:\n",
    "\n",
    "        sliding_window_mask[i][0:li] = 0\n",
    "\n",
    "sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 1, 6, 6]),\n",
       " tensor([[[[1., 0., 0., 0., 0., 0.],\n",
       "           [1., 1., 0., 0., 0., 0.],\n",
       "           [1., 1., 1., 0., 0., 0.],\n",
       "           [0., 1., 1., 1., 0., 0.],\n",
       "           [0., 0., 1., 1., 1., 0.],\n",
       "           [0., 0., 0., 1., 1., 1.]]]]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask = sliding_window_mask.unsqueeze(0)\n",
    "sliding_window_mask.shape, sliding_window_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attention_mask': tensor([[[[1., 0., 0., 0., 0., 0.],\n",
      "          [1., 1., 0., 0., 0., 0.],\n",
      "          [1., 1., 1., 0., 0., 0.],\n",
      "          [0., 1., 1., 1., 0., 0.],\n",
      "          [0., 0., 1., 1., 1., 0.],\n",
      "          [0., 0., 0., 1., 1., 1.]]]]),\n",
      " 'input_ids': tensor([[    1, 12014,   910,   460,   368,  2548]])}\n"
     ]
    }
   ],
   "source": [
    "tokenized_src_dict[\"attention_mask\"] = sliding_window_mask\n",
    "\n",
    "pprint(tokenized_src_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MixtralModel(\n",
       "  (embed_tokens): Embedding(32005, 8)\n",
       "  (layers): ModuleList(\n",
       "    (0): MixtralDecoderLayer(\n",
       "      (self_attn): MixtralSdpaAttention(\n",
       "        (q_proj): Linear(in_features=8, out_features=8, bias=False)\n",
       "        (k_proj): Linear(in_features=8, out_features=4, bias=False)\n",
       "        (v_proj): Linear(in_features=8, out_features=4, bias=False)\n",
       "        (o_proj): Linear(in_features=8, out_features=8, bias=False)\n",
       "        (rotary_emb): MixtralRotaryEmbedding()\n",
       "      )\n",
       "      (block_sparse_moe): MixtralSparseMoeBlock(\n",
       "        (gate): Linear(in_features=8, out_features=4, bias=False)\n",
       "        (experts): ModuleList(\n",
       "          (0-3): 4 x MixtralBlockSparseTop2MLP(\n",
       "            (w1): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (w2): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (w3): Linear(in_features=8, out_features=8, bias=False)\n",
       "            (act_fn): SiLU()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (input_layernorm): MixtralRMSNorm()\n",
       "      (post_attention_layernorm): MixtralRMSNorm()\n",
       "    )\n",
       "  )\n",
       "  (norm): MixtralRMSNorm()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tinymixtral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################################################################\n",
      "LLAMA DECODER FWD START\n",
      "\n",
      "Attention mask =  tensor([[[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]]]])\n",
      "\n",
      "Input (hidden states) =  tensor([[[-0.0205,  0.0033, -0.0227,  0.0090, -0.0157, -0.0196,  0.0259,\n",
      "           0.0032],\n",
      "         [ 0.0156,  0.0015,  0.0287, -0.0089,  0.0089,  0.0155, -0.0087,\n",
      "          -0.0101],\n",
      "         [-0.0133, -0.0164,  0.0127, -0.0108,  0.0175, -0.0043, -0.0097,\n",
      "           0.0199],\n",
      "         [ 0.0042, -0.0034,  0.0021, -0.0117, -0.0083,  0.0120,  0.0334,\n",
      "           0.0175],\n",
      "         [-0.0078,  0.0300, -0.0113,  0.0074,  0.0170,  0.0120, -0.0012,\n",
      "          -0.0383],\n",
      "         [-0.0140,  0.0294, -0.0047,  0.0060,  0.0086, -0.0286, -0.0195,\n",
      "           0.0427]]], grad_fn=<EmbeddingBackward0>)\n",
      "\n",
      "LayerNorm(hidden states) =  tensor([[[-1.1963,  0.1901, -1.3278,  0.5259, -0.9184, -1.1431,  1.5101,\n",
      "           0.1872],\n",
      "         [ 1.0852,  0.1033,  1.9964, -0.6169,  0.6195,  1.0772, -0.6076,\n",
      "          -0.7026],\n",
      "         [-0.9566, -1.1778,  0.9121, -0.7751,  1.2597, -0.3058, -0.6990,\n",
      "           1.4334],\n",
      "         [ 0.2787, -0.2234,  0.1394, -0.7768, -0.5505,  0.7990,  2.2188,\n",
      "           1.1619],\n",
      "         [-0.4003,  1.5348, -0.5801,  0.3767,  0.8682,  0.6159, -0.0632,\n",
      "          -1.9615],\n",
      "         [-0.6097,  1.2791, -0.2058,  0.2616,  0.3740, -1.2438, -0.8486,\n",
      "           1.8599]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "position_ids =  tensor([[0, 1, 2, 3, 4, 5]])\n",
      "bsz, query_len  =  1 6\n",
      "\n",
      "query =  tensor([[[-2.4317e-02,  3.0005e-03,  1.0064e-02, -1.0727e-01, -3.9087e-02,\n",
      "           1.3240e-03, -5.9916e-02,  8.2977e-02],\n",
      "         [-1.2701e-02,  6.1144e-03, -1.4088e-02,  9.4415e-02,  8.5527e-02,\n",
      "          -4.3866e-02,  4.6483e-02, -3.9903e-02],\n",
      "         [ 9.6255e-03,  1.2447e-01,  6.6383e-02,  3.3577e-03, -2.5601e-02,\n",
      "           1.2348e-04,  9.0148e-02, -6.5317e-02],\n",
      "         [ 3.0088e-02,  6.6576e-02,  8.3207e-03, -6.3840e-02, -1.6522e-02,\n",
      "          -8.4684e-02,  1.7307e-02,  2.8523e-02],\n",
      "         [-4.5867e-02, -2.2584e-02, -6.2673e-02,  5.3766e-02,  1.0826e-01,\n",
      "          -2.7717e-02, -5.8768e-02,  9.9162e-02],\n",
      "         [ 1.8099e-02,  6.8153e-02,  6.8070e-02,  4.5351e-02, -4.9041e-02,\n",
      "          -3.6117e-02, -4.7914e-02, -8.1207e-02]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "key =  tensor([[[ 0.0002, -0.0163, -0.0740,  0.1318],\n",
      "         [ 0.0107,  0.0231,  0.1412, -0.1121],\n",
      "         [-0.0582, -0.0852, -0.0010, -0.0617],\n",
      "         [ 0.0354, -0.0031,  0.0278,  0.0185],\n",
      "         [ 0.0854,  0.0305,  0.0678, -0.0290],\n",
      "         [-0.0050, -0.0115,  0.0315,  0.0075]]], grad_fn=<UnsafeViewBackward0>)\n",
      "value =  tensor([[[ 0.0112, -0.0299,  0.0317, -0.0445],\n",
      "         [ 0.0384,  0.0472, -0.0398,  0.0336],\n",
      "         [-0.0358,  0.0217,  0.0193,  0.0889],\n",
      "         [ 0.0085,  0.1030, -0.0138,  0.0682],\n",
      "         [-0.0063, -0.1437, -0.0108, -0.0527],\n",
      "         [ 0.0063, -0.0075,  0.0422,  0.0699]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "torch.Size([1, 6, 8]) torch.Size([1, 6, 4]) torch.Size([1, 6, 4])\n",
      "\n",
      "torch.Size([1, 4, 6, 2]) torch.Size([1, 2, 6, 2]) torch.Size([1, 2, 6, 2])\n",
      "\n",
      "kv_seq_len =  6\n",
      "\n",
      "max_position_embeddings =  32768\n",
      "Cos =  tensor([[ 1.0000,  1.0000],\n",
      "        [ 0.5403,  0.5403],\n",
      "        [-0.4161, -0.4161],\n",
      "        [-0.9900, -0.9900],\n",
      "        [-0.6536, -0.6536],\n",
      "        [ 0.2837,  0.2837]])\n",
      "\n",
      "Sin =  tensor([[ 0.0000,  0.0000],\n",
      "        [ 0.8415,  0.8415],\n",
      "        [ 0.9093,  0.9093],\n",
      "        [ 0.1411,  0.1411],\n",
      "        [-0.7568, -0.7568],\n",
      "        [-0.9589, -0.9589]])\n",
      "\n",
      "Rotated query =  tensor([[[[-0.0243,  0.0030],\n",
      "          [-0.0120, -0.0074],\n",
      "          [-0.1172, -0.0430],\n",
      "          [-0.0392, -0.0617],\n",
      "          [ 0.0129,  0.0495],\n",
      "          [ 0.0705,  0.0020]],\n",
      "\n",
      "         [[ 0.0101, -0.1073],\n",
      "          [-0.0871,  0.0392],\n",
      "          [-0.0307,  0.0590],\n",
      "          [ 0.0008,  0.0644],\n",
      "          [ 0.0817,  0.0123],\n",
      "          [ 0.0628, -0.0524]],\n",
      "\n",
      "         [[-0.0391,  0.0013],\n",
      "          [ 0.0831,  0.0483],\n",
      "          [ 0.0105, -0.0233],\n",
      "          [ 0.0283,  0.0815],\n",
      "          [-0.0917, -0.0638],\n",
      "          [-0.0485,  0.0368]],\n",
      "\n",
      "         [[-0.0599,  0.0830],\n",
      "          [ 0.0587,  0.0176],\n",
      "          [ 0.0219,  0.1092],\n",
      "          [-0.0212, -0.0258],\n",
      "          [ 0.1135, -0.0203],\n",
      "          [-0.0915,  0.0229]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "Rotated key =  tensor([[[[ 0.0002, -0.0163],\n",
      "          [-0.0137,  0.0215],\n",
      "          [ 0.1017, -0.0174],\n",
      "          [-0.0346,  0.0080],\n",
      "          [-0.0327, -0.0845],\n",
      "          [-0.0124,  0.0015]],\n",
      "\n",
      "         [[-0.0740,  0.1318],\n",
      "          [ 0.1706,  0.0582],\n",
      "          [ 0.0566,  0.0248],\n",
      "          [-0.0302, -0.0144],\n",
      "          [-0.0662, -0.0323],\n",
      "          [ 0.0162, -0.0281]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "RIGHT BEFORE ATTN :- \n",
      "\n",
      "Q =  tensor([[[[-0.0243,  0.0030],\n",
      "          [-0.0120, -0.0074],\n",
      "          [-0.1172, -0.0430],\n",
      "          [-0.0392, -0.0617],\n",
      "          [ 0.0129,  0.0495],\n",
      "          [ 0.0705,  0.0020]],\n",
      "\n",
      "         [[ 0.0101, -0.1073],\n",
      "          [-0.0871,  0.0392],\n",
      "          [-0.0307,  0.0590],\n",
      "          [ 0.0008,  0.0644],\n",
      "          [ 0.0817,  0.0123],\n",
      "          [ 0.0628, -0.0524]],\n",
      "\n",
      "         [[-0.0391,  0.0013],\n",
      "          [ 0.0831,  0.0483],\n",
      "          [ 0.0105, -0.0233],\n",
      "          [ 0.0283,  0.0815],\n",
      "          [-0.0917, -0.0638],\n",
      "          [-0.0485,  0.0368]],\n",
      "\n",
      "         [[-0.0599,  0.0830],\n",
      "          [ 0.0587,  0.0176],\n",
      "          [ 0.0219,  0.1092],\n",
      "          [-0.0212, -0.0258],\n",
      "          [ 0.1135, -0.0203],\n",
      "          [-0.0915,  0.0229]]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "K =  tensor([[[[ 0.0002, -0.0163],\n",
      "          [-0.0137,  0.0215],\n",
      "          [ 0.1017, -0.0174],\n",
      "          [-0.0346,  0.0080],\n",
      "          [-0.0327, -0.0845],\n",
      "          [-0.0124,  0.0015]],\n",
      "\n",
      "         [[ 0.0002, -0.0163],\n",
      "          [-0.0137,  0.0215],\n",
      "          [ 0.1017, -0.0174],\n",
      "          [-0.0346,  0.0080],\n",
      "          [-0.0327, -0.0845],\n",
      "          [-0.0124,  0.0015]],\n",
      "\n",
      "         [[-0.0740,  0.1318],\n",
      "          [ 0.1706,  0.0582],\n",
      "          [ 0.0566,  0.0248],\n",
      "          [-0.0302, -0.0144],\n",
      "          [-0.0662, -0.0323],\n",
      "          [ 0.0162, -0.0281]],\n",
      "\n",
      "         [[-0.0740,  0.1318],\n",
      "          [ 0.1706,  0.0582],\n",
      "          [ 0.0566,  0.0248],\n",
      "          [-0.0302, -0.0144],\n",
      "          [-0.0662, -0.0323],\n",
      "          [ 0.0162, -0.0281]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "V =  tensor([[[[ 0.0112, -0.0299],\n",
      "          [ 0.0384,  0.0472],\n",
      "          [-0.0358,  0.0217],\n",
      "          [ 0.0085,  0.1030],\n",
      "          [-0.0063, -0.1437],\n",
      "          [ 0.0063, -0.0075]],\n",
      "\n",
      "         [[ 0.0112, -0.0299],\n",
      "          [ 0.0384,  0.0472],\n",
      "          [-0.0358,  0.0217],\n",
      "          [ 0.0085,  0.1030],\n",
      "          [-0.0063, -0.1437],\n",
      "          [ 0.0063, -0.0075]],\n",
      "\n",
      "         [[ 0.0317, -0.0445],\n",
      "          [-0.0398,  0.0336],\n",
      "          [ 0.0193,  0.0889],\n",
      "          [-0.0138,  0.0682],\n",
      "          [-0.0108, -0.0527],\n",
      "          [ 0.0422,  0.0699]],\n",
      "\n",
      "         [[ 0.0317, -0.0445],\n",
      "          [-0.0398,  0.0336],\n",
      "          [ 0.0193,  0.0889],\n",
      "          [-0.0138,  0.0682],\n",
      "          [-0.0108, -0.0527],\n",
      "          [ 0.0422,  0.0699]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "True\n",
      "tensor([[[[ 0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00, -3.4028e+38,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "           -3.4028e+38],\n",
      "          [-3.4028e+38, -3.4028e+38, -3.4028e+38,  0.0000e+00,  0.0000e+00,\n",
      "            0.0000e+00]]]])\n",
      "ATTN OUTPUT =  tensor([[[[ 0.0112, -0.0299],\n",
      "          [ 0.0248,  0.0086],\n",
      "          [ 0.0047,  0.0130],\n",
      "          [ 0.0037,  0.0573],\n",
      "          [-0.0112, -0.0062],\n",
      "          [ 0.0028, -0.0160]],\n",
      "\n",
      "         [[ 0.0112, -0.0299],\n",
      "          [ 0.0248,  0.0087],\n",
      "          [ 0.0047,  0.0130],\n",
      "          [ 0.0037,  0.0573],\n",
      "          [-0.0113, -0.0062],\n",
      "          [ 0.0028, -0.0162]],\n",
      "\n",
      "         [[ 0.0317, -0.0445],\n",
      "          [-0.0043, -0.0052],\n",
      "          [ 0.0037,  0.0260],\n",
      "          [-0.0115,  0.0635],\n",
      "          [-0.0018,  0.0346],\n",
      "          [ 0.0059,  0.0284]],\n",
      "\n",
      "         [[ 0.0317, -0.0445],\n",
      "          [-0.0042, -0.0053],\n",
      "          [ 0.0037,  0.0258],\n",
      "          [-0.0114,  0.0636],\n",
      "          [-0.0017,  0.0350],\n",
      "          [ 0.0058,  0.0284]]]], grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "SA OUTPUT =  tensor([[[ 8.5693e-04, -8.4662e-04,  1.4658e-03,  1.2231e-03,  1.6009e-03,\n",
      "           3.5980e-04, -1.0710e-03,  1.5701e-03],\n",
      "         [-8.5480e-04, -4.6229e-04, -2.8992e-04,  7.1790e-05, -4.6940e-04,\n",
      "           3.3089e-04,  3.2598e-05,  1.1919e-03],\n",
      "         [-4.4477e-04,  7.0532e-04, -5.9762e-04, -7.9699e-04, -1.9645e-04,\n",
      "          -6.6960e-04,  6.7209e-04, -4.9457e-04],\n",
      "         [-2.1304e-03,  2.0274e-03, -1.6052e-03, -2.0819e-03, -1.4704e-03,\n",
      "          -1.8510e-03,  1.5074e-03, -1.6401e-03],\n",
      "         [ 7.1337e-04,  5.0488e-04, -8.2343e-04, -8.1675e-04, -3.3030e-05,\n",
      "          -1.8039e-04,  9.0701e-04, -1.2630e-03],\n",
      "         [ 8.8190e-04,  6.5856e-05, -7.8390e-04, -5.9789e-04,  2.5963e-04,\n",
      "           1.4621e-04,  8.8148e-04, -4.5098e-04]]],\n",
      "       grad_fn=<UnsafeViewBackward0>)\n",
      "\n",
      "ATTN DONE\n",
      "\n",
      "residual + hidden_states =  tensor([[[-0.0196,  0.0024, -0.0213,  0.0102, -0.0141, -0.0192,  0.0248,\n",
      "           0.0048],\n",
      "         [ 0.0147,  0.0010,  0.0284, -0.0088,  0.0084,  0.0158, -0.0087,\n",
      "          -0.0089],\n",
      "         [-0.0138, -0.0157,  0.0121, -0.0116,  0.0173, -0.0049, -0.0091,\n",
      "           0.0194],\n",
      "         [ 0.0021, -0.0013,  0.0005, -0.0138, -0.0098,  0.0102,  0.0349,\n",
      "           0.0159],\n",
      "         [-0.0071,  0.0305, -0.0122,  0.0065,  0.0169,  0.0119, -0.0003,\n",
      "          -0.0396],\n",
      "         [-0.0131,  0.0294, -0.0055,  0.0054,  0.0089, -0.0284, -0.0186,\n",
      "           0.0423]]], grad_fn=<AddBackward0>)\n",
      "Post attention norm hidden_states :-  tensor([[[-1.1940,  0.1465, -1.2939,  0.6222, -0.8592, -1.1688,  1.5078,\n",
      "           0.2904],\n",
      "         [ 1.0467,  0.0726,  2.0168, -0.6245,  0.5989,  1.1229, -0.6177,\n",
      "          -0.6323],\n",
      "         [-1.0018, -1.1421,  0.8807, -0.8434,  1.2622, -0.3587, -0.6593,\n",
      "           1.4165],\n",
      "         [ 0.1351, -0.0874,  0.0323, -0.9003, -0.6377,  0.6653,  2.2816,\n",
      "           1.0361],\n",
      "         [-0.3569,  1.5310, -0.6104,  0.3285,  0.8500,  0.5952, -0.0165,\n",
      "          -1.9877],\n",
      "         [-0.5778,  1.2966, -0.2427,  0.2382,  0.3897, -1.2515, -0.8194,\n",
      "           1.8612]]], grad_fn=<MulBackward0>)\n",
      "\n",
      "***************************************************************************\n",
      "SPARSE BLOCK MOE START\n",
      "\n",
      "Router logits =  tensor([[-0.0032, -0.0482,  0.0332, -0.0160],\n",
      "        [-0.0102,  0.0712, -0.0517,  0.0003],\n",
      "        [ 0.0885, -0.0172, -0.0019, -0.0231],\n",
      "        [-0.0117,  0.0283,  0.0430, -0.0417],\n",
      "        [-0.0454,  0.0197, -0.0536,  0.0346],\n",
      "        [ 0.0254, -0.0019,  0.0736, -0.0205]], grad_fn=<MmBackward0>)\n",
      "\n",
      "Router weights =  tensor([[0.2512, 0.2402, 0.2605, 0.2480],\n",
      "        [0.2466, 0.2675, 0.2366, 0.2492],\n",
      "        [0.2697, 0.2427, 0.2464, 0.2412],\n",
      "        [0.2458, 0.2559, 0.2597, 0.2386],\n",
      "        [0.2414, 0.2576, 0.2394, 0.2615],\n",
      "        [0.2514, 0.2446, 0.2638, 0.2401]], grad_fn=<SoftmaxBackward0>)\n",
      "\n",
      "After selection :- \n",
      "\n",
      "Selected experts =  tensor([[2, 0],\n",
      "        [1, 3],\n",
      "        [0, 2],\n",
      "        [2, 1],\n",
      "        [3, 1],\n",
      "        [2, 0]])\n",
      "\n",
      "Routing weights =  tensor([[0.2605, 0.2512],\n",
      "        [0.2675, 0.2492],\n",
      "        [0.2697, 0.2464],\n",
      "        [0.2597, 0.2559],\n",
      "        [0.2615, 0.2576],\n",
      "        [0.2638, 0.2514]], grad_fn=<TopkBackward0>)\n",
      "\n",
      "Avergared routing weights =  tensor([[0.5091, 0.4909],\n",
      "        [0.5177, 0.4823],\n",
      "        [0.5226, 0.4774],\n",
      "        [0.5037, 0.4963],\n",
      "        [0.5037, 0.4963],\n",
      "        [0.5121, 0.4879]], grad_fn=<DivBackward0>)\n",
      "\n",
      "Expert mask = tensor([[[0, 0, 1, 0, 0, 0],\n",
      "         [1, 0, 0, 0, 0, 1]],\n",
      "\n",
      "        [[0, 1, 0, 0, 0, 0],\n",
      "         [0, 0, 0, 1, 1, 0]],\n",
      "\n",
      "        [[1, 0, 0, 1, 0, 1],\n",
      "         [0, 0, 1, 0, 0, 0]],\n",
      "\n",
      "        [[0, 0, 0, 0, 1, 0],\n",
      "         [0, 1, 0, 0, 0, 0]]])\n",
      "\n",
      "W1 PROJ =  tensor([[ 0.0018, -0.0021,  0.0020,  0.0039, -0.0791, -0.0755, -0.0111,  0.0611],\n",
      "        [-0.0258, -0.0187, -0.0983,  0.0030,  0.0440,  0.0357, -0.0696, -0.0077],\n",
      "        [-0.0298, -0.0790, -0.0499, -0.0019, -0.0149, -0.0616, -0.0725, -0.0390]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "W3 PROJ =  tensor([[-0.0082, -0.0883, -0.0946,  0.0140, -0.0667, -0.1311,  0.0647,  0.0161],\n",
      "        [ 0.0225, -0.0679, -0.0663, -0.0125,  0.0879,  0.0320, -0.0503,  0.0111],\n",
      "        [-0.0190,  0.0059, -0.0476, -0.0095,  0.0509, -0.0089, -0.1948,  0.0007]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "ACT (W1 PROJ * W3 PROJ) =  tensor([[-7.2313e-06,  9.2442e-05, -9.3095e-05,  2.7249e-05,  2.5327e-03,\n",
      "          4.7590e-03, -3.5649e-04,  5.0819e-04],\n",
      "        [-2.8655e-04,  6.3023e-04,  3.1000e-03, -1.8771e-05,  1.9770e-03,\n",
      "          5.8186e-04,  1.6880e-03, -4.2538e-05],\n",
      "        [ 2.7805e-04, -2.2347e-04,  1.1585e-03,  9.1365e-06, -3.7518e-04,\n",
      "          2.6549e-04,  6.8090e-03, -1.4217e-05]], grad_fn=<MulBackward0>)\n",
      "\n",
      "W2 PROJ =  tensor([[ 1.1654e-04,  1.3819e-04, -6.6333e-05, -1.5369e-04, -5.1906e-05,\n",
      "          1.9820e-04,  1.3896e-05,  4.3925e-05],\n",
      "        [-4.5423e-06,  8.9336e-05,  8.1732e-05, -2.9854e-05,  1.4484e-04,\n",
      "          6.0888e-05, -1.1692e-06, -4.3029e-05],\n",
      "        [-1.2639e-04,  2.7181e-05, -2.0960e-05, -9.9605e-05,  1.9434e-04,\n",
      "          1.1682e-04,  1.3273e-04, -2.5704e-04]], grad_fn=<MmBackward0>)\n",
      "W1 PROJ =  tensor([[-0.0170, -0.0030,  0.0234,  0.0128, -0.0712,  0.0239,  0.0940, -0.0030],\n",
      "        [-0.0043, -0.0466, -0.0338,  0.0387,  0.0099,  0.0241, -0.0796, -0.0051],\n",
      "        [ 0.0578,  0.0061, -0.0064, -0.0402, -0.0403,  0.0153, -0.0575, -0.0108]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "W3 PROJ =  tensor([[ 0.0018,  0.0318,  0.0590, -0.0220, -0.0412,  0.0841,  0.0700, -0.0398],\n",
      "        [-0.0650,  0.0590,  0.0342,  0.0255,  0.0729, -0.0164,  0.0119,  0.0300],\n",
      "        [ 0.0737, -0.0093, -0.0581, -0.0170, -0.0341,  0.0643, -0.0147,  0.0449]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "ACT (W1 PROJ * W3 PROJ) =  tensor([[-1.5517e-05, -4.7473e-05,  6.9839e-04, -1.4102e-04,  1.4135e-03,\n",
      "          1.0165e-03,  3.4415e-03,  5.9225e-05],\n",
      "        [ 1.4011e-04, -1.3404e-03, -5.6971e-04,  5.0180e-04,  3.6158e-04,\n",
      "         -2.0037e-04, -4.5641e-04, -7.6075e-05],\n",
      "        [ 2.1910e-03, -2.8290e-05,  1.8545e-04,  3.3554e-04,  6.7282e-04,\n",
      "          4.9537e-04,  4.1109e-04, -2.4123e-04]], grad_fn=<MulBackward0>)\n",
      "\n",
      "W2 PROJ =  tensor([[-7.9863e-05, -2.4884e-05,  6.4511e-05,  5.0976e-05, -6.6119e-06,\n",
      "          2.8541e-05, -1.7764e-04,  9.8596e-05],\n",
      "        [-1.4714e-05, -5.1840e-05,  1.6635e-05, -3.5403e-06,  3.4154e-05,\n",
      "         -5.1270e-05,  4.4149e-05, -2.1173e-05],\n",
      "        [ 2.0780e-05, -7.4064e-05,  7.4532e-05,  8.3685e-05,  2.8297e-05,\n",
      "          2.2224e-05, -6.2197e-05,  5.6548e-07]], grad_fn=<MmBackward0>)\n",
      "W1 PROJ =  tensor([[-0.0521, -0.0186, -0.0367, -0.0807,  0.0016, -0.1046,  0.0332, -0.0155],\n",
      "        [ 0.0439,  0.0259,  0.0260, -0.0723, -0.0733,  0.0220, -0.0418,  0.0730],\n",
      "        [-0.0586,  0.0523, -0.0233, -0.0470,  0.0094,  0.0628,  0.0268,  0.0222],\n",
      "        [ 0.0393, -0.0216,  0.0318,  0.0564,  0.0294, -0.0179, -0.0600, -0.0245]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "W3 PROJ =  tensor([[-0.0478,  0.0182,  0.0502, -0.2013, -0.0212,  0.0347, -0.0216, -0.0172],\n",
      "        [-0.1180,  0.0218, -0.0074, -0.0868, -0.0214,  0.0011, -0.0339, -0.0940],\n",
      "        [ 0.0665,  0.0074,  0.0828, -0.0106, -0.0139, -0.0785,  0.0302,  0.0414],\n",
      "        [ 0.0636, -0.1025, -0.0261,  0.0660, -0.0629, -0.0454,  0.0455,  0.0747]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "ACT (W1 PROJ * W3 PROJ) =  tensor([[ 1.2133e-03, -1.6784e-04, -9.0353e-04,  7.7926e-03, -1.6559e-05,\n",
      "         -1.7187e-03, -3.6344e-04,  1.3208e-04],\n",
      "        [-2.6468e-03,  2.8669e-04, -9.7194e-05,  3.0236e-03,  7.5717e-04,\n",
      "          1.2101e-05,  6.9341e-04, -3.5590e-03],\n",
      "        [-1.8889e-03,  1.9809e-04, -9.5374e-04,  2.4375e-04, -6.5534e-05,\n",
      "         -2.5449e-03,  4.1019e-04,  4.6516e-04],\n",
      "        [ 1.2746e-03,  1.0958e-03, -4.2247e-04,  1.9120e-03, -9.3803e-04,\n",
      "          4.0159e-04, -1.3248e-03, -9.0511e-04]], grad_fn=<MulBackward0>)\n",
      "\n",
      "W2 PROJ =  tensor([[ 2.4030e-05,  4.6581e-05, -2.2510e-04,  9.9320e-05, -1.1765e-04,\n",
      "         -2.3847e-04, -1.4641e-04, -4.3784e-05],\n",
      "        [-2.2514e-06, -6.5316e-06, -8.4000e-05,  1.3786e-04, -1.6944e-04,\n",
      "         -8.4526e-05, -1.2189e-04, -5.1166e-05],\n",
      "        [ 7.2666e-05, -1.1493e-04, -1.0534e-04, -3.2275e-05, -5.9423e-06,\n",
      "          5.3646e-06, -8.6759e-07, -4.8192e-05],\n",
      "        [ 5.8822e-05,  3.9135e-05, -6.7574e-05,  7.4861e-05, -1.2301e-04,\n",
      "         -3.0819e-06, -6.4140e-05, -1.5658e-05]], grad_fn=<MmBackward0>)\n",
      "W1 PROJ =  tensor([[ 0.0131,  0.0240,  0.0099,  0.0751,  0.0339,  0.0192,  0.0469,  0.0531],\n",
      "        [ 0.0071, -0.0741,  0.0475,  0.0404,  0.0771, -0.0460,  0.0060,  0.0260]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "W3 PROJ =  tensor([[ 0.0854, -0.0562,  0.0539,  0.0114, -0.0115,  0.0346,  0.0126, -0.0018],\n",
      "        [-0.0606, -0.0048,  0.0588,  0.0985,  0.0088,  0.0983, -0.0336, -0.1446]],\n",
      "       grad_fn=<MmBackward0>)\n",
      "\n",
      "ACT (W1 PROJ * W3 PROJ) =  tensor([[ 5.6437e-04, -6.8315e-04,  2.6965e-04,  4.4410e-04, -1.9757e-04,\n",
      "          3.3621e-04,  3.0302e-04, -5.0359e-05],\n",
      "        [-2.1532e-04,  1.7029e-04,  1.4293e-03,  2.0281e-03,  3.5066e-04,\n",
      "         -2.2082e-03, -1.0056e-04, -1.9000e-03]], grad_fn=<MulBackward0>)\n",
      "\n",
      "W2 PROJ =  tensor([[ 1.9186e-06,  4.4061e-06, -3.7613e-05,  4.9049e-05, -2.2179e-05,\n",
      "         -3.3190e-05, -3.2150e-05,  3.0266e-06],\n",
      "        [ 5.2463e-05,  1.1020e-04, -1.0301e-04,  5.0114e-05, -6.6078e-05,\n",
      "         -8.8891e-05,  6.7483e-05, -1.2933e-05]], grad_fn=<MmBackward0>)\n",
      "Final hidden states =  tensor([[[ 1.0003e-05,  6.7571e-05, -7.4471e-05,  3.5906e-05,  1.1206e-05,\n",
      "          -9.1508e-05, -7.5108e-05, -4.3413e-05],\n",
      "         [-1.6044e-05,  4.0264e-05, -1.6281e-05,  5.0561e-05, -3.5291e-05,\n",
      "          -2.8094e-05, -5.9420e-05,  4.4807e-05],\n",
      "         [ 8.8984e-05,  9.0899e-05, -6.6925e-05, -4.4576e-05, -8.5851e-05,\n",
      "           1.0210e-04, -2.3360e-05,  1.5479e-05],\n",
      "         [-8.4367e-06, -2.9019e-05, -3.4052e-05,  6.7680e-05, -6.8389e-05,\n",
      "          -6.8020e-05, -3.9481e-05, -3.6280e-05],\n",
      "         [ 1.1279e-05, -3.4536e-05,  1.8041e-05,  6.6238e-05,  2.8705e-06,\n",
      "          -5.6899e-06, -4.7061e-05,  1.8052e-06],\n",
      "         [-2.4465e-05, -4.5586e-05, -6.4165e-05, -6.5129e-05,  9.1785e-05,\n",
      "           5.9748e-05,  6.4321e-05, -1.5010e-04]]], grad_fn=<ViewBackward0>)\n",
      "\n",
      "***************************************************************************\n",
      "residual + hidden_states :-  tensor([[[-0.0196,  0.0025, -0.0214,  0.0103, -0.0141, -0.0193,  0.0247,\n",
      "           0.0047],\n",
      "         [ 0.0147,  0.0011,  0.0284, -0.0087,  0.0084,  0.0158, -0.0088,\n",
      "          -0.0089],\n",
      "         [-0.0137, -0.0156,  0.0120, -0.0116,  0.0172, -0.0048, -0.0091,\n",
      "           0.0195],\n",
      "         [ 0.0021, -0.0014,  0.0005, -0.0137, -0.0098,  0.0101,  0.0349,\n",
      "           0.0158],\n",
      "         [-0.0071,  0.0305, -0.0121,  0.0066,  0.0169,  0.0118, -0.0004,\n",
      "          -0.0396],\n",
      "         [-0.0131,  0.0294, -0.0056,  0.0053,  0.0089, -0.0284, -0.0185,\n",
      "           0.0421]]], grad_fn=<AddBackward0>)\n",
      "\n",
      "OUTPUTS =  (tensor([[[-0.0196,  0.0025, -0.0214,  0.0103, -0.0141, -0.0193,  0.0247,\n",
      "           0.0047],\n",
      "         [ 0.0147,  0.0011,  0.0284, -0.0087,  0.0084,  0.0158, -0.0088,\n",
      "          -0.0089],\n",
      "         [-0.0137, -0.0156,  0.0120, -0.0116,  0.0172, -0.0048, -0.0091,\n",
      "           0.0195],\n",
      "         [ 0.0021, -0.0014,  0.0005, -0.0137, -0.0098,  0.0101,  0.0349,\n",
      "           0.0158],\n",
      "         [-0.0071,  0.0305, -0.0121,  0.0066,  0.0169,  0.0118, -0.0004,\n",
      "          -0.0396],\n",
      "         [-0.0131,  0.0294, -0.0056,  0.0053,  0.0089, -0.0284, -0.0185,\n",
      "           0.0421]]], grad_fn=<AddBackward0>),)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output = tinymixtral(**tokenized_src_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "my_project_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
